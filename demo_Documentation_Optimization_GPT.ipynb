{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ueUZmcVgU52T",
        "dtFn2zfneLpF",
        "XQ0a20l5d58p",
        "TrKhzqLdgmb-",
        "KHmAR63E8J_R",
        "wXJSiu-O8kbe",
        "-XwN-Qn_hrq_",
        "Yw2_x3t6ho3s",
        "wucxMvdpP_-7",
        "HRHS5x__QQea",
        "b-WNJxIWQetk",
        "sBpunIGdQtWT",
        "LMA-6K2Tlsgx",
        "NqlsAjk_TwMf",
        "wCB0_p1XA3Eu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Read in all the required documents\n",
        "\n",
        "## If your docs are all chunked and stored in the Matching Enginee, this document-loading part does not need to be run."
      ],
      "metadata": {
        "id": "ueUZmcVgU52T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in your documents to local environment"
      ],
      "metadata": {
        "id": "sGucyusiPJda"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentation Optimization\n"
      ],
      "metadata": {
        "id": "ZoRVQ3_9y4SV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try the method of \"question_ansering_documentâ€œ from Google Generative AI\n",
        "\n"
      ],
      "metadata": {
        "id": "W3OjJM1-s4D5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some preparation steps, there is a \"utils\" folder in one of the Google's Github repo, it is an important one that contains some key functions to make the rest work. At the end of this section, there are some variable for google cloud project. I was using the one Jon created. Feel free to adjust it if there is need"
      ],
      "metadata": {
        "id": "dtFn2zfneLpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy a required utils folder from github\n",
        "\n",
        "%%capture\n",
        "!git clone https://github.com/GoogleCloudPlatform/generative-ai.git\n",
        "!cp -r /content/generative-ai/language/examples/document-qa/utils /content\n",
        "\n",
        "# Install Vertex AI LLM SDK\n",
        "! pip install -U google-cloud-aiplatform==1.27.0 langchain==0.0.201\n",
        "\n",
        "# Dependencies required by Unstructured PDF loader\n",
        "! sudo apt -y -qq install tesseract-ocr libtesseract-dev\n",
        "! sudo apt-get -y -qq install poppler-utils\n",
        "! pip install -U unstructured==0.7.5 pdf2image==1.16.3 pytesseract==0.3.10 pdfminer.six\n",
        "\n",
        "# For Matching Engine integration dependencies (default embeddings)\n",
        "! pip install -U tensorflow_hub==0.13.0 tensorflow_text==2.12.1\n",
        "\n",
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# The environment will restart and just run the following cells\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "EZoAPcr778T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "import json\n",
        "import textwrap\n",
        "# Utils\n",
        "import time\n",
        "import uuid\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import vertexai\n",
        "# Vertex AI\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
        "\n",
        "# Langchain\n",
        "import langchain\n",
        "\n",
        "print(f\"LangChain version: {langchain.__version__}\")\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import GCSDirectoryLoader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Import custom Matching Engine packages\n",
        "from utils.matching_engine import MatchingEngine\n",
        "from utils.matching_engine_utils import MatchingEngineUtils\n",
        "\n",
        "\n",
        "PROJECT_ID = \"mdai-interns-summer-2023\"  # @param {type:\"string\"}\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# Initialize Vertex AI SDK\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "# Utility functions for Embeddings API with rate limiting\n",
        "def rate_limit(max_per_minute):\n",
        "    period = 60 / max_per_minute\n",
        "    print(\"Waiting\")\n",
        "    while True:\n",
        "        before = time.time()\n",
        "        yield\n",
        "        after = time.time()\n",
        "        elapsed = after - before\n",
        "        sleep_time = max(0, period - elapsed)\n",
        "        if sleep_time > 0:\n",
        "            print(\".\", end=\"\")\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "\n",
        "class CustomVertexAIEmbeddings(VertexAIEmbeddings, BaseModel):\n",
        "    requests_per_minute: int\n",
        "    num_instances_per_batch: int\n",
        "\n",
        "    # Overriding embed_documents method\n",
        "    def embed_documents(self, texts: List[str]):\n",
        "        limiter = rate_limit(self.requests_per_minute)\n",
        "        results = []\n",
        "        docs = list(texts)\n",
        "\n",
        "        while docs:\n",
        "            # Working in batches because the API accepts maximum 5\n",
        "            # documents per request to get embeddings\n",
        "            head, docs = (\n",
        "                docs[: self.num_instances_per_batch],\n",
        "                docs[self.num_instances_per_batch :],\n",
        "            )\n",
        "            chunk = self.client.get_embeddings(head)\n",
        "            results.extend(chunk)\n",
        "            next(limiter)\n",
        "\n",
        "        return [r.values for r in results]\n",
        "\n",
        "\n",
        "# Text model instance integrated with langChain\n",
        "llm = VertexAI(\n",
        "    model_name=\"text-bison@001\",\n",
        "    max_output_tokens=1024,\n",
        "    temperature=0.2,\n",
        "    top_p=0.8,\n",
        "    # top_k=40,\n",
        "    top_k=20,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Embeddings API integrated with langChain\n",
        "EMBEDDING_QPM = 100\n",
        "EMBEDDING_NUM_BATCH = 5\n",
        "embeddings = CustomVertexAIEmbeddings(\n",
        "    requests_per_minute=EMBEDDING_QPM,\n",
        "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
        ")\n",
        "\n",
        "\n",
        "ME_REGION = # your region\n",
        "ME_INDEX_NAME = # your index name @param {type:\"string\"}\n",
        "ME_EMBEDDING_DIR =  # a google cloud storage bucket @param {type:\"string\"}\n",
        "ME_DIMENSIONS = 768  # when using Vertex PaLM Embedding\n",
        "mengine = MatchingEngineUtils(PROJECT_ID, ME_REGION, ME_INDEX_NAME)"
      ],
      "metadata": {
        "id": "ewqJZE9qHe6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a86159f-0b3a-4393-98df-28a103a3d485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertex AI SDK version: 1.27.0\n",
            "LangChain version: 0.0.201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run this section of codes if the matching engine has not been deployed. (I have deployed, so this part could be skipped)"
      ],
      "metadata": {
        "id": "XQ0a20l5d58p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a Google Cloud Storage bucket for your Matching Engine index\n",
        "! gsutil mb -l us-central1 $ME_EMBEDDING_DIR"
      ],
      "metadata": {
        "id": "NedqpufXp_4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c729be31-1120-4e70-e4aa-69cba7c9b937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://mdai_matching_engine_test_1/...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy embedding\n",
        "init_embedding = {\"id\": str(uuid.uuid4()), \"embedding\": list(np.zeros(ME_DIMENSIONS))}\n",
        "\n",
        "# dump embedding to a local file\n",
        "with open(\"embeddings_0.json\", \"w\") as f:\n",
        "    json.dump(init_embedding, f)\n",
        "\n",
        "# write embedding to Cloud Storage\n",
        "! gsutil cp embeddings_0.json {ME_EMBEDDING_DIR}/init_index/embeddings_0.json"
      ],
      "metadata": {
        "id": "JWCK8vERd4vA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa28a86-9679-4cc1-d228-b73d503ff709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://embeddings_0.json [Content-Type=application/json]...\n",
            "/ [1 files][  3.8 KiB/  3.8 KiB]                                                \n",
            "Operation completed over 1 objects/3.8 KiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create index\n",
        "index = mengine.create_index(\n",
        "    embedding_gcs_uri=f\"{ME_EMBEDDING_DIR}/init_index\",\n",
        "    dimensions=ME_DIMENSIONS,\n",
        "    index_update_method=\"streaming\",\n",
        "    index_algorithm=\"tree-ah\",\n",
        ")\n",
        "if index:\n",
        "    print(index.name)"
      ],
      "metadata": {
        "id": "D8HxhvQqfwe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219ed5de-88d9-4710-f257-c856f9bc2284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......................................................projects/837432346917/locations/us-central1/indexes/4678738635535679488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_endpoint = mengine.deploy_index()\n",
        "if index_endpoint:\n",
        "    print(f\"Index endpoint resource name: {index_endpoint.name}\")\n",
        "    print(\n",
        "        f\"Index endpoint public domain name: {index_endpoint.public_endpoint_domain_name}\"\n",
        "    )\n",
        "    print(\"Deployed indexes on the index endpoint:\")\n",
        "    for d in index_endpoint.deployed_indexes:\n",
        "        print(f\"    {d.id}\")"
      ],
      "metadata": {
        "id": "F_WWpk_wgekt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea274d50-741f-40fd-9450-57eec5d32c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".................Index endpoint resource name: projects/837432346917/locations/us-central1/indexEndpoints/3170032760366563328\n",
            "Index endpoint public domain name: \n",
            "Deployed indexes on the index endpoint:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This section of code load documents into the matching enginee. If you already loaded documents before, the docs will be added to a google bucket. So be careful that repeated running will cause repeated files inserted (I have loaded into this as my project, so this part could be skipped)"
      ],
      "metadata": {
        "id": "TrKhzqLdgmb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "# The commented area loads documents from GCS\n",
        "# \"\"\"\n",
        "# # cloud bucket path\n",
        "# GCS_URL_KB = \"gs://mdai-summer-interns-2023-files/docs/content/\"\n",
        "\n",
        "# # Ingest files\n",
        "# bucket_name = GCS_URL_KB.split(\"/\")[2]\n",
        "# print(bucket_name)\n",
        "# prefix = \"/\".join(GCS_URL_KB.split(\"/\")[3:])\n",
        "# print(prefix)\n",
        "\n",
        "# print(f\"Processing documents from {GCS_URL_KB}\")\n",
        "# loader = GCSDirectoryLoader(project_name=PROJECT_ID, bucket=bucket_name, prefix=prefix, glob=\"**/*.md\")\n",
        "\n",
        "\"\"\"\n",
        "This part tries to directly read from directory within the environment\n",
        "\"\"\"\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "path = \"/content/gcs-store/docs/content\"\n",
        "loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
        "\n",
        "documents = loader.load()\n",
        "\n",
        "# Add document name and source to the metadata\n",
        "for document in documents:\n",
        "    doc_md = document.metadata\n",
        "    document_name = doc_md[\"source\"].split(\"/\")[-1]\n",
        "\n",
        "    split_list = doc_md[\"source\"].split(\"/\")\n",
        "    source = \"/\".join(split_list[:len(split_list)-1])\n",
        "\n",
        "    # This commented part works for Google cloud storage path\n",
        "\n",
        "    # doc_source_suffix = \"/\".join(doc_md[\"source\"].split(\"/\")[4:-1])\n",
        "    # source = f\"{doc_source_prefix}/{doc_source_suffix}\"\n",
        "    document.metadata = {\"source\": source, \"document_name\": document_name}\n",
        "\n",
        "print(f\"# of documents loaded (pre-chunking) = {len(documents)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1yCKnYKSvv2",
        "outputId": "ebcc0fbd-7e1e-4b68-83bf-686bd904508b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of documents loaded (pre-chunking) = 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do an extra step of filter (filter out those files with keyword \"update\" in title), we don't want unnecessary changelog files\n",
        "documents = [document for document in documents if 'updates' not in document.metadata['document_name']]\n",
        "print(len(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diDF8O22Wi2b",
        "outputId": "9386bf54-bcab-4aa0-af96-3d17c8307d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chunk documents\n",
        "\n",
        "# split the documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(documents)\n",
        "# doc_splits = text_splitter.split_documents(documents_dyllan)\n",
        "\n",
        "# Add chunk number to metadata\n",
        "for idx, split in enumerate(doc_splits):\n",
        "    split.metadata[\"chunk\"] = idx\n",
        "\n",
        "print(f\"# of documents = {len(doc_splits)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K_LNaaGl9Lp",
        "outputId": "318d178b-a731-4453-bf06-6f90d6a41772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of documents = 227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This part is created to insert an extra file outside the documentation page, (If this is already added, can skip) All these could be adjusted, code is quite similar"
      ],
      "metadata": {
        "id": "KHmAR63E8J_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is wrote to specifically insert Dyllan's code which is out of the current\n",
        "# documenation folder\n",
        "\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "path = \"/content/DICOM_SR_SEG.md\"\n",
        "loader_dyllan = TextLoader(path)\n",
        "\n",
        "documents_dyllan = loader_dyllan.load()\n",
        "\n",
        "# Add document name and source to the metadata\n",
        "for document in documents_dyllan:\n",
        "    doc_md = document.metadata\n",
        "    document_name = doc_md[\"source\"].split(\"/\")[-1]\n",
        "\n",
        "\n",
        "    # This commented part works for Google cloud storage path\n",
        "\n",
        "    # doc_source_suffix = \"/\".join(doc_md[\"source\"].split(\"/\")[4:-1])\n",
        "    # source = f\"{doc_source_prefix}/{doc_source_suffix}\"\n",
        "    document.metadata = {\"source\": \"DICOM_SR_EXPORT\", \"document_name\": document_name}\n",
        "\n",
        "print(f\"# of documents loaded (pre-chunking) = {len(documents_dyllan)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ0MqeAMzvpQ",
        "outputId": "be6f70bb-aacb-4fca-8e14-5a687603aa32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of documents loaded (pre-chunking) = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chunk documents\n",
        "\n",
        "# split the documents into chunks\n",
        "text_splitter_dyllan = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
        ")\n",
        "# doc_splits = text_splitter.split_documents(documents)\n",
        "doc_splits_dyllan = text_splitter_dyllan.split_documents(documents_dyllan)\n",
        "\n",
        "# Add chunk number to metadata\n",
        "for idx, split in enumerate(doc_splits_dyllan):\n",
        "    split.metadata[\"chunk\"] = idx\n",
        "\n",
        "print(f\"# of documents = {len(doc_splits_dyllan)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn9mgsreSv4Z",
        "outputId": "e70a8c70-ee8c-431d-f300-397c55881b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of documents = 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_splits_dyllan[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlJ24u2Z8wS6",
        "outputId": "ef2c0a5b-f278-4788-87a7-5603c6c84428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='## MD.AI Annotation to SR Export Tool\\n### Export Annotations from MD.AI\\'s platform into DICOM SR Format\\n\\nSome MD.ai packeges and some other Python packages need to be inputted. And then there is the of class \"SR_SEG_Export\". You need to have this class to be in a python file that can be accessed from your envionrment. You could then use this class to finish exporting annotation to DICOM SR format. The SR_SEG_Export class could also be found in this notebook: https://colab.research.google.com/drive/1d4I7wZhlRIS2T0nFo6dhmefi5qDHBSkW?usp=sharing\\n\\n```python\\nimport mdai.SR_SEG_Export\\n\\nmdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\\n  annotation_json = \\'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json\\',\\n  metadata_json = \\'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json\\'\\n)\\n\\n```\\n\\n\\n```python\\nimport mdai\\nimport pandas as pd\\nfrom datetime import datetime\\nimport os\\nimport requests', metadata={'source': 'DICOM_SR_EXPORT', 'document_name': 'DICOM_SR_SEG.md', 'chunk': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doc_splits = doc_splits+ doc_splits_dyllan\n",
        "# len(doc_splits)"
      ],
      "metadata": {
        "id": "p0dc2bsgA6d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifically for Dyllan's extra Dicom document\n",
        "texts = [doc.page_content for doc in doc_splits_dyllan]\n",
        "metadatas = [\n",
        "    [\n",
        "        {\"namespace\": \"source\", \"allow_list\": [doc.metadata[\"source\"]]},\n",
        "        {\"namespace\": \"document_name\", \"allow_list\": [doc.metadata[\"document_name\"]]},\n",
        "        {\"namespace\": \"chunk\", \"allow_list\": [str(doc.metadata[\"chunk\"])]},\n",
        "    ]\n",
        "    for doc in doc_splits_dyllan\n",
        "]"
      ],
      "metadata": {
        "id": "UoCu5SFGRYaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first = [doc_splits_dyllan[0]]\n",
        "texts = [doc.page_content for doc in first]\n",
        "metadatas = [\n",
        "    [\n",
        "        {\"namespace\": \"source\", \"allow_list\": [doc.metadata[\"source\"]]},\n",
        "        {\"namespace\": \"document_name\", \"allow_list\": [doc.metadata[\"document_name\"]]},\n",
        "        {\"namespace\": \"chunk\", \"allow_list\": [str(doc.metadata[\"chunk\"])]},\n",
        "    ]\n",
        "    for doc in first\n",
        "]"
      ],
      "metadata": {
        "id": "GeKQZRlj9xZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start to feed in document chunks (If the documents are already added, can skip)"
      ],
      "metadata": {
        "id": "wXJSiu-O8kbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mengine = MatchingEngineUtils(PROJECT_ID, ME_REGION, ME_INDEX_NAME)\n",
        "ME_INDEX_ID, ME_INDEX_ENDPOINT_ID = mengine.get_index_and_endpoint()\n",
        "print(f\"ME_INDEX_ID={ME_INDEX_ID}\")\n",
        "print(f\"ME_INDEX_ENDPOINT_ID={ME_INDEX_ENDPOINT_ID}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCSWzT0kT4gn",
        "outputId": "57f68b8b-a8c6-4e11-8883-2e047e6e9ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ME_INDEX_ID=projects/837432346917/locations/us-central1/indexes/4678738635535679488\n",
            "ME_INDEX_ENDPOINT_ID=projects/837432346917/locations/us-central1/indexEndpoints/3170032760366563328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize vector store\n",
        "me = MatchingEngine.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=ME_REGION,\n",
        "    gcs_bucket_name=f'gs://{ME_EMBEDDING_DIR.split(\"/\")[2]}',\n",
        "    embedding=embeddings,\n",
        "    index_id=ME_INDEX_ID,\n",
        "    endpoint_id=ME_INDEX_ENDPOINT_ID,\n",
        ")"
      ],
      "metadata": {
        "id": "qckAlxdJT4m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store docs as embeddings in Matching Engine index\n",
        "# It may take a while since API is rate limited\n",
        "texts = [doc.page_content for doc in doc_splits]\n",
        "metadatas = [\n",
        "    [\n",
        "        {\"namespace\": \"source\", \"allow_list\": [doc.metadata[\"source\"]]},\n",
        "        {\"namespace\": \"document_name\", \"allow_list\": [doc.metadata[\"document_name\"]]},\n",
        "        {\"namespace\": \"chunk\", \"allow_list\": [str(doc.metadata[\"chunk\"])]},\n",
        "    ]\n",
        "    for doc in doc_splits\n",
        "]"
      ],
      "metadata": {
        "id": "QiKR93YRT4p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert, 100 at a time, otherwise weird quota limit error might occur\n",
        "for i in range(int(len(metadatas)/100)+1):\n",
        "  print(f\"{i} start\")\n",
        "  start = i * 100\n",
        "\n",
        "  end = (i+1) * 100\n",
        "  if end <= len(metadatas):\n",
        "    doc_ids = me.add_texts(texts=texts[start:end], metadatas=metadatas[start:end])\n",
        "  else:\n",
        "    doc_ids = me.add_texts(texts=texts[start:], metadatas=metadatas[start:])\n"
      ],
      "metadata": {
        "id": "4ruAOJ4hT4sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing section"
      ],
      "metadata": {
        "id": "-XwN-Qn_hrq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mengine = MatchingEngineUtils(PROJECT_ID, ME_REGION, ME_INDEX_NAME)\n",
        "ME_INDEX_ID, ME_INDEX_ENDPOINT_ID = mengine.get_index_and_endpoint()\n",
        "print(f\"ME_INDEX_ID={ME_INDEX_ID}\")\n",
        "print(f\"ME_INDEX_ENDPOINT_ID={ME_INDEX_ENDPOINT_ID}\")\n",
        "\n",
        "# initialize vector store\n",
        "me = MatchingEngine.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=ME_REGION,\n",
        "    gcs_bucket_name=f'gs://{ME_EMBEDDING_DIR.split(\"/\")[2]}',\n",
        "    embedding=embeddings,\n",
        "    index_id=ME_INDEX_ID,\n",
        "    endpoint_id=ME_INDEX_ENDPOINT_ID,\n",
        ")"
      ],
      "metadata": {
        "id": "EYog5TTEiE8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27898528-a74c-4e73-bf9f-345400e6029f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ME_INDEX_ID=projects/837432346917/locations/us-central1/indexes/4678738635535679488\n",
            "ME_INDEX_ENDPOINT_ID=projects/837432346917/locations/us-central1/indexEndpoints/3170032760366563328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is the part that uses GPT model, the ultimate function used to generate response is called \"gpt_response_generation\""
      ],
      "metadata": {
        "id": "Yw2_x3t6ho3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the code provided by Jon to deal with some really weird situtions, when some input document text cause LLM not able to generate anything\n",
        "import requests\n",
        "import logging\n",
        "from http.client import HTTPConnection  # py3\n",
        "\n",
        "log = logging.getLogger('urllib3')\n",
        "log.setLevel(logging.DEBUG)\n",
        "\n",
        "# logging from urllib3 to console\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.DEBUG)\n",
        "log.addHandler(ch)\n",
        "\n",
        "# print statements from `http.client.HTTPConnection` to console/stdout\n",
        "HTTPConnection.debuglevel = 1"
      ],
      "metadata": {
        "id": "Roi4wLRxkwAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Write me a script that works for the whole pipeline of exporting MD.ai annotations into DICOM SR format and store to my default google bucket.\"\n",
        "# question = \"write me a script that exports annotations into DICOM SR format\""
      ],
      "metadata": {
        "id": "cOGQjhIDzbd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Start using gpt to generate response"
      ],
      "metadata": {
        "id": "HRHS5x__QQea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install --upgrade mdai\n",
        "\n",
        "import mdai\n",
        "import json\n",
        "domain = # your domain\n",
        "access_token = # your personal token\n",
        "mdai_client = mdai.Client(domain= domain, access_token= access_token)"
      ],
      "metadata": {
        "id": "m_wnO2_k06yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gpt_response_generation(me, question):\n",
        "  system_prompt1 = \" The detailed pipeline script should cover these steps 1. download the annotation and metadata json files using the mdai_client.project and mdaiclient.download_dicom_metadata functions, do not download anything else such as model output, do not convert json to dataframe 2. after downloading, find these 2 json files by searching keyword 'dicom_meta_data' and 'annotations' in it, pass them as input to do the DICOM SR export 3. then directly upload the output folder to google bucket\"\n",
        "  question_with_guideline = question + system_prompt1\n",
        "\n",
        "  res = me.similarity_search(question_with_guideline, k=7, search_distance = 0.6)\n",
        "  content = [doc.page_content for doc in res]\n",
        "  # Retrieval Prompt Template\n",
        "  template = \"\"\"SYSTEM: You are an intelligent assistant helping the users with their questions on techniques related to md.ai cloud platform products.\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  There is a set of rules:\n",
        "\n",
        "  1. Use the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
        "\n",
        "  2. If the answer is about coding, please make sure it is easy to separate text and code.\n",
        "\n",
        "  3. If there are parts that the context does not answer, and it is about coding, you can use your coding knowledge.\n",
        "\n",
        "  4. For code that interacts with MD.ai, please strictly follow the structure in context, do not create function name by yourself\n",
        "\n",
        "  5. But for conceptual questions, Do not try to make up an answer and strictly answer based on the context.\n",
        "\n",
        "  6. If the context is empty, just say \"I do not know the answer to that.\"\n",
        "\n",
        "  ============\n",
        "  {explanation}\n",
        "  ============\n",
        "\n",
        "  =============\n",
        "  {context}\n",
        "  =============\n",
        "\n",
        "  Personal Information that should be filled into code\n",
        "  =============\n",
        "  domain: staging.md.ai\n",
        "  personal token: 1234567mdai\n",
        "  project id: 1234567mdaiProject\n",
        "  dataset id: 1234567Dataset\n",
        "  google bucket name: ClarenceTest1\n",
        "  output folder: ./SR_Output\n",
        "\n",
        "\n",
        "\n",
        "  =============\n",
        "\n",
        "\n",
        "\n",
        "  Question: {question}\n",
        "  Helpful Answer:\"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
        "  \"\"\"\n",
        "  formatted_template = template.format(explanation = system_prompt1 , context='\\n'.join(content), question = question)\n",
        "  return formatted_template\n",
        "  # messages_p2 = [\n",
        "  #           {\"role\": \"user\", \"content\": formatted_template}]\n",
        "\n",
        "  # result = mdai_client.chat_completion.create(messages_p2, model='gpt-4', temperature=0)\n",
        "  # return result[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "id": "hbBOcUoH065I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_response_generation(me, question)"
      ],
      "metadata": {
        "id": "xqgTPXne88es",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38c0a9e7-d978-40ce-c04b-772c7942cdde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SYSTEM: You are an intelligent assistant helping the users with their questions on techniques related to md.ai cloud platform products.\\n\\n  Question: Write me a script that works for the whole pipeline of exporting MD.ai annotations into DICOM SR format and store to my default google bucket.\\n\\n  There is a set of rules:\\n\\n  1. Use the following pieces of context to answer the question at the end. Think step-by-step and then answer.\\n\\n  2. If the answer is about coding, please make sure it is easy to separate text and code.\\n\\n  3. If there are parts that the context does not answer, and it is about coding, you can use your coding knowledge.\\n\\n  4. For code that interacts with MD.ai, please strictly follow the structure in context, do not create function name by yourself\\n\\n  5. But for conceptual questions, Do not try to make up an answer and strictly answer based on the context.\\n\\n  6. If the context is empty, just say \"I do not know the answer to that.\"\\n\\n  ============\\n   The detailed pipeline script should cover these steps 1. download the annotation and metadata json files using the mdai_client.project and mdaiclient.download_dicom_metadata functions, do not download anything else such as model output, do not convert json to dataframe 2. after downloading, find these 2 json files by searching keyword \\'dicom_meta_data\\' and \\'annotations\\' in it, pass them as input to do the DICOM SR export 3. then directly upload the output folder to google bucket\\n  ============\\n\\n  =============\\n  ## MD.AI Annotation to SR Export Tool\\n### Export Annotations from MD.AI\\'s platform into DICOM SR Format\\n\\nSome MD.ai packeges and some other Python packages need to be inputted. And then there is the of class \"SR_SEG_Export\". You need to have this class to be in a python file that can be accessed from your envionrment. You could then use this class to finish exporting annotation to DICOM SR format. The SR_SEG_Export class could also be found in this notebook: https://colab.research.google.com/drive/1d4I7wZhlRIS2T0nFo6dhmefi5qDHBSkW?usp=sharing\\n\\n```python\\nimport mdai.SR_SEG_Export\\n\\nmdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\\n  annotation_json = \\'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json\\',\\n  metadata_json = \\'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json\\'\\n)\\n\\n```\\n\\n\\n```python\\nimport mdai\\nimport pandas as pd\\nfrom datetime import datetime\\nimport os\\nimport requests\\nExample output\\n\\npy\\nUsing working directory for data.\\nPreparing annotations export for project MwBe19Br...\\nSuccess: annotations data for project MwBe19Br ready.\\nDownloading file: mdai_public_project_MwBe19Br_annotations_labelgroup_all_2020-09-23-214038.json\\nNo project created. Downloaded annotations only.\\n\\nDownload model outputs\\n\\n```py\\n\\nDownload only the model outputs data\\n\\np = mdai_client.download_model_outputs(PROJECT_ID, DATASET_ID, MODEL_ID, path=\\'.\\')\\n```\\n\\nExample output\\n\\npy\\nUsing working directory for model outputs.\\nPreparing model-outputs export for project MwBe19Br...\\nSuccess: model-outputs data for project MwBe19Br ready.\\nDownloading file: mdai_public_project_MwBe19Br_model-outputs_2020-09-23-214038.json\\n\\nDownload DICOM metadata\\n\\nYou can download the DICOM metadata in either json or csv format.\\n\\n```py\\n\\nDownload only the DICOM metadata\\n\\np = mdai_client.download_dicom_metadata(PROJECT_ID, DATASET_ID, format =\"json\", path=\\'.\\')\\n```\\n\\nExample output\\nExample output\\n\\npy\\nUsing working directory for dicom metadata.\\nPreparing dicom-metadata export for project MwBe19Br...\\nSuccess: dicom-metadata data for project MwBe19Br ready.\\nDownloading file: mdai_public_project_MwBe19Br_dicom_metadata_2020-09-23-214038.json\\n\\nAnnotations dataframe and csv\\n\\nCopy the downloaded file name from the output above or from your downloaded json file. If you get a json error, try downloading outside of your firewall.\\n\\n```py\\n\\nReplace with your filename\\n\\nJSON = \\'mdai_public_project_MwBe19Br_annotations_labelgroup_all_2020-09-23-214038.json\\'\\nresults = mdai.common_utils.json_to_dataframe(JSON)\\n\\nAnnotations dataframe\\n\\nannots_df = results[\\'annotations\\']\\n\\ncsv\\n\\nannots_df.to_csv(\\'project_csv.csv\\', index=False)\\n```\\n\\nNotebooks\\n\\nDownload and/or upload annotations\\n\\nThe linked notebook gives examples for using the mdai library to\\n\\ndownload annotations from your project\\n\\nturn the exported file into a Pandas dataframe\\n\\nand import data back into your project\\n1. Download JSON\\n\\nOption 1: Download JSON file directly from the UI using the Export tab and drag JSON file into working director\\n\\nOption 2: Use mdai library to download JSON\\n\\nCreate Client\\n\\n```py\\nimport mdai\\n\\nGet variables from project info tab and user settings\\n\\nDOMAIN = \\'public.md.ai\\'\\nYOUR_PERSONAL_TOKEN = \\'a1s2d3f4g4h5h59797kllh8vk\\'\\nPROJECT_ID = \\'MwBe19Br\\' # project info\\nmdai_client = mdai.Client(domain=DOMAIN, access_token=YOUR_PERSONAL_TOKEN)\\n```\\n\\nExample output\\n\\npy\\nSuccessfully authenticated to public.md.ai.\\n\\nDownload annotations\\n\\n```py\\n\\nDownload only the annotation data\\n\\np = mdai_client.project(PROJECT_ID, path=\\'.\\',  annotations_only=True)\\n```\\n\\nExample output\\n\\npy\\nUsing working directory for data.\\nPreparing annotations export for project MwBe19Br...\\nSuccess: annotations data for project MwBe19Br ready.\\nDownloading file: mdai_public_project_MwBe19Br_annotations_labelgroup_all_2020-09-23-214038.json\\nNo project created. Downloaded annotations only.\\n\\n2. JSON to Dataframe\\nThe exported data may also be scoped by individual datasets by specifying dataset_id. By default, all datasets within the project will be included.\\n\\nExample:\\n\\npy\\np = mdai_client.project(\\'LxR6zdR2\\', path=\\'./lesson3-data\\')\\n\\nA project object will attempt to download the dataset (images and annotations separately) and extract images, annotations to the specified path. However, if the latest version of images or annotations have been downloaded and extracted, then cached data is used.\\n\\nCreate Project if annotations_only=True\\n\\nIf you are unable to export images from within the Annotator, this feature was turned off in order to save money for your institution/company. To use the MD.ai API using locally available images you need to do two things -\\n\\nImages need to be in a specific format. Project requires the images to be in StudyInstanceUID/SeriesInstanceUID/SOPInstanceUID.dcm format.\\n\\nDownload the annotations and create the project:\\nHow-To Guides\\n\\n!!! warning\\n\\nQuick start: Download annotations and convert to dataframe/ csv\\n\\nAccess project\\n\\n```py\\nimport mdai\\n\\nGet variables from project info tab and user settings\\n\\nDOMAIN = \\'public.md.ai\\'\\nYOUR_PERSONAL_TOKEN = \\'a1s2d3f4g4h5h59797kllh8vk\\'\\nPROJECT_ID = \\'MwBe19Br\\'\\nmdai_client = mdai.Client(domain=DOMAIN, access_token=YOUR_PERSONAL_TOKEN)\\n```\\n\\nExample output\\n\\npy\\nSuccessfully authenticated to public.md.ai.\\n\\nDownload annotations\\n\\n```py\\n\\nDownload the annotation data only (all label groups)\\n\\np = mdai_client.project(PROJECT_ID, path=\\'.\\',  annotations_only=True)\\n\\nDownload the annotation data only for a specific label group (by label group hash ID)\\n\\np = mdai_client.project(PROJECT_ID, path=\\'.\\',  annotations_only=True, label_group_id=LABEL_GROUP_ID)\\n```\\n\\nExample output\\n## MD.AI Annotation to SR Export Tool\\n### Export Annotations from MD.AI\\'s platform into DICOM SR Format\\n\\nSome MD.ai packeges and some other Python packages need to be inputted. And then there is the of class \"SR_SEG_Export\". You need to have this class to be in a python file that can be accessed from your envionrment. You could then use this class to finish exporting annotation to DICOM SR format. The SR_SEG_Export class could also be found in this notebook: https://colab.research.google.com/drive/1d4I7wZhlRIS2T0nFo6dhmefi5qDHBSkW?usp=sharing\\n\\n```python\\nimport mdai.SR_SEG_Export\\n\\nmdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\\n  annotation_json = \\'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json\\',\\n  metadata_json = \\'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json\\'\\n)\\n\\n```\\n\\n\\n```python\\nimport mdai\\nimport pandas as pd\\nfrom datetime import datetime\\nimport os\\nimport requests\\n\\nimport pydicom\\nfrom pydicom.filereader import dcmread\\nfrom pydicom.dataset import Dataset\\n\\n# Imports and Parse Some of the DICOM Standard Files\\n# -----------------------------------------------\\nclass SR_SEG_Export:\\n  class SR_Export:\\n    def __init__(self, annotation_json, metadata_json):\\n      self.Annotation_Json = annotation_json\\n      self.Metadata_Json = metadata_json\\n\\n      self.dicom_standards_setups()\\n      self.dicom_tags_setup()\\n      self.create_exports()\\n    \\n    def dicom_standards_setups(self):\\n\\n      ctm_json = requests.get(\\'https://raw.githubusercontent.com/innolitics/dicom-standard/master/standard/ciod_to_modules.json\\').text\\n      mta_json = requests.get(\\'https://raw.githubusercontent.com/innolitics/dicom-standard/master/standard/module_to_attributes.json\\').text\\n      attributes_json = requests.get(\\'https://raw.githubusercontent.com/innolitics/dicom-standard/master/standard/attributes.json\\').text\\n      # ciod_to_modules_dataframe\\n      ctm_df = pd.read_json(ctm_json)\\n      # module_to_attributes_dataframe\\n      mta_df = pd.read_json(mta_json)\\n      # attributes_dataframe\\n      attributes_df = pd.read_json(attributes_json)\\n\\n      # Select basic-text-sr modules\\n      SR_modules_df = ctm_df[ctm_df[\\'ciodId\\'] == \\'basic-text-sr\\']\\n      # Select all basic-text-sr attributes\\n      SR_attributes_df = mta_df[mta_df[\\'moduleId\\'].isin(SR_modules_df[\\'moduleId\\'])]\\n\\n      attribute_to_keyword_map = dict(zip(attributes_df[\\'tag\\'], attributes_df[\\'keyword\\']))\\n      self.keyword_to_VR_map = dict(zip(attributes_df[\\'keyword\\'], attributes_df[\\'valueRepresentation\\']))\\n      attribute_to_type_map = dict(zip(SR_attributes_df[\\'tag\\'], SR_attributes_df[\\'type\\']))\\n\\n      self.keyword_to_type_map = {}\\n      for attribute in attribute_to_type_map:\\n        self.keyword_to_type_map[attribute_to_keyword_map[attribute]] = attribute_to_type_map[attribute]\\n\\n      # Create dicom heirarchy for SR document (modeled after the Standard DICOM Browser)\\n      # ---------------------------------------------------\\n      SR_attributes_df.sort_values(\\'path\\')\\n      self.dicom_tag_heirarchy = {}\\n      for _, row in SR_attributes_df.iterrows():\\n        if row[\\'path\\'].count(\\':\\') == 1:\\n          self.dicom_tag_heirarchy[attribute_to_keyword_map[row[\\'tag\\']]] = {}\\n        else:\\n          paths = row[\\'path\\'].split(\\':\\')\\n          #convert all tags in path to tag format\\n          parents = []\\n          for parent in paths[1:-1]:\\n            parent = f\\'({parent[:4]},{parent[4:]})\\'.upper()\\n            parent = attribute_to_keyword_map[parent]\\n            parents.append(parent)\\n\\n          child = paths[-1]\\n          child = f\\'({child[:4]},{child[4:]})\\'.upper()\\n          child = attribute_to_keyword_map[child]\\n\\n          #get to last tag sequence\\n          current_sequence = self.dicom_tag_heirarchy[parents[0]]\\n          for parent in parents[1:]:\\n            current_sequence = current_sequence[parent]\\n          current_sequence[child] = {}\\n\\n      # Dictionary of VR and their corresponding types\\n      self.typos ={\\n          \\'AE\\': str,\\n          \\'AS\\': str,\\n          \\'AT\\': pydicom.tag.BaseTag,\\n          \\'CS\\': str,\\n          \\'DA\\': str,\\n          \\'DS\\': pydicom.valuerep.DSfloat,\\n          \\'DT\\': str,\\n          \\'FL\\': float,\\n          \\'FD\\': float,\\n          \\'IS\\': pydicom.valuerep.IS,\\n          \\'LO\\': str,\\n          \\'LT\\': str,\\n          \\'OB\\': bytes,\\n          \\'OB or OW\\': bytes,\\n          \\'OD\\': bytes,\\n          \\'OF\\': bytes,\\n          \\'OL\\': bytes,\\n          \\'OV\\': bytes,\\n          \\'OW\\': bytes,\\n          \\'PN\\': pydicom.valuerep.PersonName,\\n          \\'SH\\': str,\\n          \\'SL\\': int,\\n          \\'SQ\\': pydicom.sequence.Sequence,\\n          \\'SS\\': int,\\n          \\'ST\\': str,\\n          \\'SV\\': int,\\n          \\'TM\\': str,\\n          \\'UC\\': str,\\n          \\'UI\\': pydicom.uid.UID,\\n          \\'UL\\': int,\\n          \\'UN\\': bytes,\\n          \\'UR\\': str,\\n          \\'US\\': int,\\n          \\'US or SS\\': int,\\n          \\'UT\\': str,\\n          \\'UV\\': int,\\n      }\\n\\n    def dicom_tags_setup(self):\\n      # Read Imported JSONs\\n      results = mdai.common_utils.json_to_dataframe(os.getcwd() + \\'/\\' + self.Annotation_Json)\\n      self.metadata = pd.read_json(os.getcwd() + \\'/\\' + self.Metadata_Json)\\n\\n      # Annotations dataframe\\n      self.annots_df = results[\\'annotations\\']\\n      labels = results[\\'labels\\']\\n      self.label_name_map = dict(zip(labels.labelId, labels.labelName))\\n      self.label_scope_map = dict(zip(labels.labelId, labels.scope))\\n\\n      # Images DICOM Tags dataframe\\n      tags = []\\n      for dataset in self.metadata[\\'datasets\\']:\\n        tags.extend(dataset[\\'dicomMetadata\\'])\\n\\n      # Create organization of study, series, instance UID & dicom tags\\n      # ----------------------------------------------------------\\n      self.studies = self.annots_df.StudyInstanceUID.unique()\\n      self.tags_df = pd.DataFrame.from_dict(tags) # dataframe of study, series, instance UID & dicom tags\\n      self.dicom_hierarchy = {}\\n      for tag in tags:\\n        study_uid = tag[\\'StudyInstanceUID\\']\\n        series_uid = tag[\\'SeriesInstanceUID\\']\\n        sop_uid = tag[\\'SOPInstanceUID\\']\\n\\n        # Check if already seen study_uid yet (avoids key error)\\n        if study_uid not in self.dicom_hierarchy: # Using study_uid bc rn it\\'s exam level\\n          self.dicom_hierarchy[study_uid] = []\\n\\n        # Dicom_heirarchy is a dictionary with study_uid as keys and a list as value\\n        # each list contains a dictionary with the series_uid as a key and a list of sop_uids as value\\n        if not any(series_uid in d for d in self.dicom_hierarchy[study_uid]):\\n          self.dicom_hierarchy[study_uid].append({series_uid:[]})\\n        for d in self.dicom_hierarchy[study_uid]: #loops through item in dicom_heriarchy list (just the series_uid dict)\\n          if series_uid in d:\\n            d[series_uid].append(sop_uid)\\n  =============\\n\\n  Personal Information that should be filled into code\\n  =============\\n  domain: staging.md.ai \\n  personal token: 1234567mdai\\n  project id: 1234567mdaiProject\\n  dataset id: 1234567Dataset\\n  google bucket name: ClarenceTest1 \\n  output folder: ./SR_Output\\n   \\n\\n\\n  =============\\n\\n\\n\\n  Question: Write me a script that works for the whole pipeline of exporting MD.ai annotations into DICOM SR format and store to my default google bucket.\\n  Helpful Answer:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The generated response:"
      ],
      "metadata": {
        "id": "b-WNJxIWQetk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure, here is a Python script that should accomplish this task. Please replace the placeholders with your actual values.\n",
        "\n",
        "```python\n",
        "import os\n",
        "import mdai\n",
        "from google.cloud import storage\n",
        "\n",
        "# Define your personal information\n",
        "DOMAIN = 'staging.md.ai'\n",
        "YOUR_PERSONAL_TOKEN = '1234567mdai'\n",
        "PROJECT_ID = '1234567mdaiProject'\n",
        "DATASET_ID = '1234567Dataset'\n",
        "GOOGLE_BUCKET_NAME = 'ClarenceTest1'\n",
        "OUTPUT_FOLDER = './SR_Output'\n",
        "\n",
        "# Create mdai client\n",
        "mdai_client = mdai.Client(domain=DOMAIN, access_token=YOUR_PERSONAL_TOKEN)\n",
        "\n",
        "# Download only the annotation data\n",
        "p = mdai_client.project(PROJECT_ID, path='.',  annotations_only=True)\n",
        "\n",
        "# Download only the DICOM metadata\n",
        "p = mdai_client.download_dicom_metadata(PROJECT_ID, DATASET_ID, format =\"json\", path='.')\n",
        "\n",
        "# Find the downloaded json files\n",
        "annotation_json = [f for f in os.listdir('.') if 'annotations' in f][0]\n",
        "metadata_json = [f for f in os.listdir('.') if 'dicom_meta_data' in f][0]\n",
        "\n",
        "# Export annotations to DICOM SR format\n",
        "import mdai.SR_SEG_Export\n",
        "mdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\n",
        "  annotation_json = annotation_json,\n",
        "  metadata_json = metadata_json\n",
        ")\n",
        "\n",
        "# Upload the output folder to Google Cloud Storage\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket(GOOGLE_BUCKET_NAME)\n",
        "blobs = bucket.list_blobs()\n",
        "\n",
        "for blob in blobs:\n",
        "    file_path = os.path.join(OUTPUT_FOLDER, blob.name)\n",
        "    blob.upload_from_filename(file_path)\n",
        "```\n",
        "\n",
        "This script first downloads the annotation and metadata json files using the mdai_client.project and mdai_client.download_dicom_metadata functions. It then finds these json files and passes them as input to the DICOM SR export function. Finally, it uploads the output folder to your specified Google Cloud Storage bucket."
      ],
      "metadata": {
        "id": "GUSllcrwR3VM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Best Version of the response"
      ],
      "metadata": {
        "id": "sBpunIGdQtWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Based on the data obtained from the link [https://link](https://link), the content suggests a process to export MD.ai annotations into DICOM SR format and store them in a Google bucket. Here is a step-by-step guide:\n",
        "\n",
        "1. First, we need to download the annotation and metadata JSON files. This can be done using the `mdai_client.project` and `mdai_client.download_dicom_metadata` functions.\n",
        "\n",
        "```python\n",
        "import mdai\n",
        "\n",
        "DOMAIN = 'http://md.ai'\n",
        "YOUR_PERSONAL_TOKEN = '1234567mdai'\n",
        "PROJECT_ID = '1234567mdaiProject'\n",
        "DATASET_ID = '1234567Dataset'\n",
        "mdai_client = mdai.Client(domain=DOMAIN, access_token=YOUR_PERSONAL_TOKEN)\n",
        "\n",
        "# Download the annotation data\n",
        "p = mdai_client.project(PROJECT_ID, path='.',  annotations_only=True)\n",
        "\n",
        "# Download the DICOM metadata\n",
        "p = mdai_client.download_dicom_metadata(PROJECT_ID, DATASET_ID, format =\"json\", path='.')\n",
        "```\n",
        "\n",
        "2. After downloading, we need to read in the path of these two files as input to do the DICOM SR export.\n",
        "\n",
        "```python\n",
        "import mdai.SR_SEG_Export\n",
        "\n",
        "mdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\n",
        "  annotation_json = 'mdai_public_project_MwBe19Br_annotations_labelgroup_all_2020-09-23-214038.json',\n",
        "  metadata_json = 'mdai_public_project_MwBe19Br_dicom_metadata_2020-09-23-214038.json'\n",
        ")\n",
        "```\n",
        "\n",
        "3. Finally, we need to upload the output folder to the Google bucket.\n",
        "\n",
        "```python\n",
        "from google.cloud import storage\n",
        "\n",
        "def upload_to_bucket(bucket_name, source_file_name, destination_blob_name):\n",
        "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "    blob.upload_from_filename(source_file_name)\n",
        "\n",
        "    print(\n",
        "        \"File {} uploaded to {}.\".format(\n",
        "            source_file_name, destination_blob_name\n",
        "        )\n",
        "    )\n",
        "\n",
        "upload_to_bucket('ClarenceTest1', './SR_Output', 'SR_Output')\n",
        "```\n",
        "\n",
        "Please replace the placeholders with your actual data. This script should help you achieve your goal."
      ],
      "metadata": {
        "id": "FbMJV9CkMtan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is the part that uses Google PaLM model, the utlimate function used to generate is called \"ask\""
      ],
      "metadata": {
        "id": "LMA-6K2Tlsgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Question/Answering Chain with Vector Store using Text\n",
        "\n",
        "# Create chain to answer questions\n",
        "NUMBER_OF_RESULTS = 5\n",
        "SEARCH_DISTANCE_THRESHOLD = 0.6\n",
        "\n",
        "# Expose index to the retriever\n",
        "retriever = me.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\n",
        "        \"k\": NUMBER_OF_RESULTS,\n",
        "        \"search_distance\": SEARCH_DISTANCE_THRESHOLD,\n",
        "    },\n",
        ")\n"
      ],
      "metadata": {
        "id": "pPeqI2C2WT-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieval Prompt Template\n",
        "template = \"\"\"SYSTEM: You are an intelligent assistant helping the users with their questions on techniques related to md.ai cloud platform products.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "There is a set of rules:\n",
        "\n",
        "1. Use the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
        "\n",
        "2. If the answer is about coding, please make sure it is easy to separate text and code.\n",
        "\n",
        "3. If there are parts that the context does not answer, and it is about coding, you can use your coding knowledge.\n",
        "\n",
        "4. If the context has a link, always directly include the link in the response\n",
        "\n",
        "5. But for conceptual questions, Do not try to make up an answer and strictly answer based on the context.\n",
        "\n",
        "6. If the context is empty, just say \"I do not know the answer to that.\"\n",
        "\n",
        "\n",
        "=============\n",
        "{context}\n",
        "=============\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "\"\"\"\n",
        " - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aM3m0NH9WUKH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3500bac-1231-4791-a96e-7fc708354fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n - If the answer to the question cannot be determined from the context alone, say \"I cannot determine the answer to that.\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure RetrievalQA chain\n",
        "\n",
        "# Uses LLM to synthesize results from the search index.\n",
        "# Use Vertex PaLM Text API for LLM\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    verbose=True,\n",
        "    chain_type_kwargs={\n",
        "        \"prompt\": PromptTemplate(\n",
        "            template=template,\n",
        "            input_variables=[\"context\", \"question\"],\n",
        "        ),\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "s__xstQYWceF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable for troubleshooting\n",
        "qa.combine_documents_chain.verbose = True\n",
        "qa.combine_documents_chain.llm_chain.verbose = True\n",
        "qa.combine_documents_chain.llm_chain.llm.verbose = True"
      ],
      "metadata": {
        "id": "d9XUQdRXWchF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main functions\n",
        "\n",
        "def formatter(result):\n",
        "    print(f\"Query: {result['query']}\")\n",
        "    print(\".\" * 80)\n",
        "    if \"source_documents\" in result.keys():\n",
        "        for idx, ref in enumerate(result[\"source_documents\"]):\n",
        "            print(\"-\" * 80)\n",
        "            print(f\"REFERENCE #{idx}\")\n",
        "            print(\"-\" * 80)\n",
        "            if \"score\" in ref.metadata:\n",
        "                print(f\"Matching Score: {ref.metadata['score']}\")\n",
        "            if \"source\" in ref.metadata:\n",
        "                print(f\"Document Source: {ref.metadata['source']}\")\n",
        "            if \"document_name\" in ref.metadata:\n",
        "                print(f\"Document Name: {ref.metadata['document_name']}\")\n",
        "            print(\".\" * 80)\n",
        "            print(f\"Content: \\n{wrap(ref.page_content)}\")\n",
        "    print(\".\" * 80)\n",
        "    response = wrap(result['result'])\n",
        "    print(f\"Response: {response}\")\n",
        "    print(\".\" * 80)\n",
        "    return response\n",
        "\n",
        "\n",
        "def wrap(s):\n",
        "    return \"\\n\".join(textwrap.wrap(s, width=120, break_long_words=False))\n",
        "\n",
        "\n",
        "def ask(query, qa=qa, k=NUMBER_OF_RESULTS, search_distance=SEARCH_DISTANCE_THRESHOLD):\n",
        "    qa.retriever.search_kwargs[\"search_distance\"] = search_distance\n",
        "    qa.retriever.search_kwargs[\"k\"] = k\n",
        "    result = qa({\"query\": query})\n",
        "    print(result)\n",
        "    return formatter(result)"
      ],
      "metadata": {
        "id": "SIUniqtBWcll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### This is the part that I try to answer a list of questions in a file called \"questions.txtâ€œ and format the response in a csv form"
      ],
      "metadata": {
        "id": "NqlsAjk_TwMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import pandas as pd\n",
        "response_list = []\n",
        "with open('/content/questions.txt', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Split the content by newline\n",
        "question_list = content.split('\\n')\n",
        "for question in question_list:\n",
        "  response_list.append(ask(question))\n"
      ],
      "metadata": {
        "id": "O-pUH-_f3TMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"PaLM_systemPrompt1_neighbor3_threshold0.6.csv\", index = False)"
      ],
      "metadata": {
        "id": "Ju8hWDxbrLCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'prompt': question_list, 'response': response_list})\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1032
        },
        "id": "nzsLlPGuqu1Q",
        "outputId": "1c9b2a4a-9181-447d-c148-de53c69b5623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               prompt  \\\n",
              "0          What is Md.ai command line interface tool?   \n",
              "1                                      What is Md.ai?   \n",
              "2                      What should I have for dinner?   \n",
              "3                                Do you like dolphin?   \n",
              "4                           Does MD.ai support de-id?   \n",
              "5   Show me the example code to download MD.ai ann...   \n",
              "6   How can I perform segmentation on <some anatom...   \n",
              "7   How can I quickly segment <some region of inte...   \n",
              "8   Show me how to render images from one plane to...   \n",
              "9   How would I provide sub-classification on a la...   \n",
              "10  Why can't I upload my data stored in Google cl...   \n",
              "11    Why can't I download the images in the dataset?   \n",
              "12  How should I start to annotate my medical images?   \n",
              "13  Will my patient data get leaked while using MD...   \n",
              "14  I am an admin staff working at a doctorâ€™s offi...   \n",
              "15  What deep learning models do MD.ai currently s...   \n",
              "16  How should I deploy a self-trained model? Is t...   \n",
              "17  How could teachers use MD.ai cloud platform, a...   \n",
              "18  I have a annotation json as my input, my acces...   \n",
              "19  Give me the code pipeline that export annotati...   \n",
              "\n",
              "                                             response  \n",
              "0   The MD.ai CLI is a command line interface tool...  \n",
              "1   MD.ai is a cloud platform for medical image an...  \n",
              "2                   I do not know the answer to that.  \n",
              "3                   I do not know the answer to that.  \n",
              "4   Yes, MD.ai supports de-id. It has a separate D...  \n",
              "5   The following code can be used to download MD....  \n",
              "6   To perform segmentation on <some anatomical st...  \n",
              "7   To quickly segment <some region of interest> a...  \n",
              "8   To render images from one plane to other plane...  \n",
              "9   To provide sub-classification on a label, you ...  \n",
              "10  There are a few reasons why you might not be a...  \n",
              "11  There are a few reasons why you might not be a...  \n",
              "12  To start annotating your medical images, you c...  \n",
              "13  MD.ai provides a suite of tools for all your d...  \n",
              "14  MD.ai cloud platform can help you speed up you...  \n",
              "15  MD.ai supports a variety of deep learning mode...  \n",
              "16  To deploy a self-trained model on the MD.ai pl...  \n",
              "17  Teachers can use MD.ai cloud platform to creat...  \n",
              "18  Sure, here is a script that converts an annota...  \n",
              "19  The code pipeline to export annotations from M...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-109e7df4-9f0c-428d-a25d-a8133d119045\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is Md.ai command line interface tool?</td>\n",
              "      <td>The MD.ai CLI is a command line interface tool...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is Md.ai?</td>\n",
              "      <td>MD.ai is a cloud platform for medical image an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What should I have for dinner?</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Do you like dolphin?</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does MD.ai support de-id?</td>\n",
              "      <td>Yes, MD.ai supports de-id. It has a separate D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Show me the example code to download MD.ai ann...</td>\n",
              "      <td>The following code can be used to download MD....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How can I perform segmentation on &lt;some anatom...</td>\n",
              "      <td>To perform segmentation on &lt;some anatomical st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How can I quickly segment &lt;some region of inte...</td>\n",
              "      <td>To quickly segment &lt;some region of interest&gt; a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Show me how to render images from one plane to...</td>\n",
              "      <td>To render images from one plane to other plane...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How would I provide sub-classification on a la...</td>\n",
              "      <td>To provide sub-classification on a label, you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Why can't I upload my data stored in Google cl...</td>\n",
              "      <td>There are a few reasons why you might not be a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Why can't I download the images in the dataset?</td>\n",
              "      <td>There are a few reasons why you might not be a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How should I start to annotate my medical images?</td>\n",
              "      <td>To start annotating your medical images, you c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Will my patient data get leaked while using MD...</td>\n",
              "      <td>MD.ai provides a suite of tools for all your d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I am an admin staff working at a doctorâ€™s offi...</td>\n",
              "      <td>MD.ai cloud platform can help you speed up you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What deep learning models do MD.ai currently s...</td>\n",
              "      <td>MD.ai supports a variety of deep learning mode...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How should I deploy a self-trained model? Is t...</td>\n",
              "      <td>To deploy a self-trained model on the MD.ai pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How could teachers use MD.ai cloud platform, a...</td>\n",
              "      <td>Teachers can use MD.ai cloud platform to creat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I have a annotation json as my input, my acces...</td>\n",
              "      <td>Sure, here is a script that converts an annota...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Give me the code pipeline that export annotati...</td>\n",
              "      <td>The code pipeline to export annotations from M...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-109e7df4-9f0c-428d-a25d-a8133d119045')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-7c4cefc9-1bb6-4e42-ac0e-699d5a8a125e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c4cefc9-1bb6-4e42-ac0e-699d5a8a125e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-7c4cefc9-1bb6-4e42-ac0e-699d5a8a125e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-109e7df4-9f0c-428d-a25d-a8133d119045 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-109e7df4-9f0c-428d-a25d-a8133d119045');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'prompt': question_list, 'response': response_list})\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "emn1FC96o77r",
        "outputId": "00501268-926b-46a0-fee9-e264711e71fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               prompt  \\\n",
              "0          What is Md.ai command line interface tool?   \n",
              "1                                      What is Md.ai?   \n",
              "2                      What should I have for dinner?   \n",
              "3                                Do you like dolphin?   \n",
              "4                           Does MD.ai support de-id?   \n",
              "5   Show me the example code to download MD.ai ann...   \n",
              "6   How can I perform segmentation on <some anatom...   \n",
              "7   How can I quickly segment <some region of inte...   \n",
              "8   Show me how to render images from one plane to...   \n",
              "9   How would I provide sub-classification on a la...   \n",
              "10  Why can't I upload my data stored in Google cl...   \n",
              "11    Why can't I download the images in the dataset?   \n",
              "12  How should I start to annotate my medical images?   \n",
              "13  Will my patient data get leaked while using MD...   \n",
              "14  I am an admin staff working at a doctorâ€™s offi...   \n",
              "15  What deep learning models do MD.ai currently s...   \n",
              "16  How should I deploy a self-trained model? Is t...   \n",
              "17  How could teachers use MD.ai cloud platform, a...   \n",
              "18  I have a annotation json as my input, my acces...   \n",
              "19  Give me the code pipeline that export annotati...   \n",
              "\n",
              "                                             response  \n",
              "0   The MD.ai CLI is a convenient tool for efficie...  \n",
              "1   MD.ai is a cloud platform for medical imaging ...  \n",
              "2                   I do not know the answer to that.  \n",
              "3                   I do not know the answer to that.  \n",
              "4   Yes, MD.ai provides a suite of tools for all y...  \n",
              "5   The code to download MD.ai annotations is as f...  \n",
              "6   To perform segmentation on <some anatomical st...  \n",
              "7   Interpolation helps solve this problem by aski...  \n",
              "8                   I do not know the answer to that.  \n",
              "9                   I do not know the answer to that.  \n",
              "10  There are a few reasons why you might not be a...  \n",
              "11  There are a few reasons why you might not be a...  \n",
              "12  To annotate your medical images, you can use t...  \n",
              "13  MD.ai provides a secure platform for storing a...  \n",
              "14  MD.ai Annotator is a web-based annotation tool...  \n",
              "15                  I do not know the answer to that.  \n",
              "16  Before following the steps for deploying your ...  \n",
              "17  MD.ai cloud platform is a web-based platform t...  \n",
              "18  Sure, here is the script:  ```py import json i...  \n",
              "19  The code pipeline to export annotations from M...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-ec2a0ff0-9736-4755-81f2-5c7f21a46073\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is Md.ai command line interface tool?</td>\n",
              "      <td>The MD.ai CLI is a convenient tool for efficie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is Md.ai?</td>\n",
              "      <td>MD.ai is a cloud platform for medical imaging ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What should I have for dinner?</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Do you like dolphin?</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does MD.ai support de-id?</td>\n",
              "      <td>Yes, MD.ai provides a suite of tools for all y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Show me the example code to download MD.ai ann...</td>\n",
              "      <td>The code to download MD.ai annotations is as f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How can I perform segmentation on &lt;some anatom...</td>\n",
              "      <td>To perform segmentation on &lt;some anatomical st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How can I quickly segment &lt;some region of inte...</td>\n",
              "      <td>Interpolation helps solve this problem by aski...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Show me how to render images from one plane to...</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How would I provide sub-classification on a la...</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Why can't I upload my data stored in Google cl...</td>\n",
              "      <td>There are a few reasons why you might not be a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Why can't I download the images in the dataset?</td>\n",
              "      <td>There are a few reasons why you might not be a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How should I start to annotate my medical images?</td>\n",
              "      <td>To annotate your medical images, you can use t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Will my patient data get leaked while using MD...</td>\n",
              "      <td>MD.ai provides a secure platform for storing a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I am an admin staff working at a doctorâ€™s offi...</td>\n",
              "      <td>MD.ai Annotator is a web-based annotation tool...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What deep learning models do MD.ai currently s...</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How should I deploy a self-trained model? Is t...</td>\n",
              "      <td>Before following the steps for deploying your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How could teachers use MD.ai cloud platform, a...</td>\n",
              "      <td>MD.ai cloud platform is a web-based platform t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I have a annotation json as my input, my acces...</td>\n",
              "      <td>Sure, here is the script:  ```py import json i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Give me the code pipeline that export annotati...</td>\n",
              "      <td>The code pipeline to export annotations from M...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec2a0ff0-9736-4755-81f2-5c7f21a46073')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-3027226b-fa96-44c7-af7f-3228b728d9c6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3027226b-fa96-44c7-af7f-3228b728d9c6')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-3027226b-fa96-44c7-af7f-3228b728d9c6 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec2a0ff0-9736-4755-81f2-5c7f21a46073 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec2a0ff0-9736-4755-81f2-5c7f21a46073');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'prompt': question_list, 'response': response_list})\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1859
        },
        "id": "KekKJR9zNowS",
        "outputId": "ec2dc0fa-688b-48d6-a765-bfe840e83811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               prompt  \\\n",
              "0          What is Md.ai command line interface tool?   \n",
              "1                                      What is Md.ai?   \n",
              "2                      What should I have for dinner?   \n",
              "3                                Do you like dolphin?   \n",
              "4                           Does MD.ai support de-id?   \n",
              "5   Show me the example code to download MD.ai ann...   \n",
              "6   How can I perform segmentation on <some anatom...   \n",
              "7   How can I quickly segment <some region of inte...   \n",
              "8   Show me how to render images from one plane to...   \n",
              "9   How would I provide sub-classification on a la...   \n",
              "10  Why can't I upload my data stored in Google cl...   \n",
              "11    Why can't I download the images in the dataset?   \n",
              "12  How should I start to annotate my medical images?   \n",
              "13  Will my patient data get leaked while using MD...   \n",
              "14  I am an admin staff working at a doctorâ€™s offi...   \n",
              "15  What deep learning models do MD.ai currently s...   \n",
              "16  How should I deploy a self-trained model? Is t...   \n",
              "17  How could teachers use MD.ai cloud platform, a...   \n",
              "18  I have a annotation json as my input, my acces...   \n",
              "19  Give me the code pipeline that export annotati...   \n",
              "\n",
              "                                             response  \n",
              "0   The MD.ai CLI is a convenient tool for efficie...  \n",
              "1   MD.ai is a cloud platform for medical image an...  \n",
              "2                   I do not know the answer to that.  \n",
              "3                   I do not know the answer to that.  \n",
              "4   Yes, MD.ai provides a suite of tools for all y...  \n",
              "5   The following code snippet shows how to downlo...  \n",
              "6   To perform segmentation on <some anatomical st...  \n",
              "7   To quickly segment <some region of interest> a...  \n",
              "8   To render images from one plane to other plane...  \n",
              "9   To provide sub-classification on a label, you ...  \n",
              "10  There are a few possible reasons why you might...  \n",
              "11  There are a few reasons why you might not be a...  \n",
              "12  To get started, we recommend looking at severa...  \n",
              "13  MD.ai provides a suite of tools for all your d...  \n",
              "14  The MD.ai cloud platform can help you speed up...  \n",
              "15  MD.ai currently supports TensorFlow, PyTorch, ...  \n",
              "16  To deploy a self-trained model on the MD.ai pl...  \n",
              "17  Teachers can use MD.ai cloud platform to creat...  \n",
              "18  Sure, here is a script that converts an annota...  \n",
              "19  The code pipeline to export annotations from M...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-86c3ac96-d64c-41e3-b22b-9d23287f1725\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is Md.ai command line interface tool?</td>\n",
              "      <td>The MD.ai CLI is a convenient tool for efficie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is Md.ai?</td>\n",
              "      <td>MD.ai is a cloud platform for medical image an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What should I have for dinner?</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Do you like dolphin?</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does MD.ai support de-id?</td>\n",
              "      <td>Yes, MD.ai provides a suite of tools for all y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Show me the example code to download MD.ai ann...</td>\n",
              "      <td>The following code snippet shows how to downlo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How can I perform segmentation on &lt;some anatom...</td>\n",
              "      <td>To perform segmentation on &lt;some anatomical st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How can I quickly segment &lt;some region of inte...</td>\n",
              "      <td>To quickly segment &lt;some region of interest&gt; a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Show me how to render images from one plane to...</td>\n",
              "      <td>To render images from one plane to other plane...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How would I provide sub-classification on a la...</td>\n",
              "      <td>To provide sub-classification on a label, you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Why can't I upload my data stored in Google cl...</td>\n",
              "      <td>There are a few possible reasons why you might...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Why can't I download the images in the dataset?</td>\n",
              "      <td>There are a few reasons why you might not be a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How should I start to annotate my medical images?</td>\n",
              "      <td>To get started, we recommend looking at severa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Will my patient data get leaked while using MD...</td>\n",
              "      <td>MD.ai provides a suite of tools for all your d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I am an admin staff working at a doctorâ€™s offi...</td>\n",
              "      <td>The MD.ai cloud platform can help you speed up...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What deep learning models do MD.ai currently s...</td>\n",
              "      <td>MD.ai currently supports TensorFlow, PyTorch, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How should I deploy a self-trained model? Is t...</td>\n",
              "      <td>To deploy a self-trained model on the MD.ai pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How could teachers use MD.ai cloud platform, a...</td>\n",
              "      <td>Teachers can use MD.ai cloud platform to creat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I have a annotation json as my input, my acces...</td>\n",
              "      <td>Sure, here is a script that converts an annota...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Give me the code pipeline that export annotati...</td>\n",
              "      <td>The code pipeline to export annotations from M...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86c3ac96-d64c-41e3-b22b-9d23287f1725')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-704b675b-20bb-4b59-bd6d-4e6dde2db9de\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-704b675b-20bb-4b59-bd6d-4e6dde2db9de')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-704b675b-20bb-4b59-bd6d-4e6dde2db9de button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86c3ac96-d64c-41e3-b22b-9d23287f1725 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86c3ac96-d64c-41e3-b22b-9d23287f1725');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'prompt': question_list, 'response': response_list})\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1574
        },
        "id": "wELm7X194Rox",
        "outputId": "f11b80b1-ec1a-4015-f8e0-e39dc5fca961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               prompt  \\\n",
              "0          What is Md.ai command line interface tool?   \n",
              "1                                      What is Md.ai?   \n",
              "2                      What should I have for dinner?   \n",
              "3                                Do you like dolphin?   \n",
              "4                           Does MD.ai support de-id?   \n",
              "5   Show me the example code to download MD.ai ann...   \n",
              "6   How can I perform segmentation on <some anatom...   \n",
              "7   How can I quickly segment <some region of inte...   \n",
              "8   Show me how to render images from one plane to...   \n",
              "9   How would I provide sub-classification on a la...   \n",
              "10  Why can't I upload my data stored in Google cl...   \n",
              "11    Why can't I download the images in the dataset?   \n",
              "12  How should I start to annotate my medical images?   \n",
              "13  Will my patient data get leaked while using MD...   \n",
              "14  I am an admin staff working at a doctorâ€™s offi...   \n",
              "15  What deep learning models do MD.ai currently s...   \n",
              "16  How should I deploy a self-trained model? Is t...   \n",
              "17  How could teachers use MD.ai cloud platform, a...   \n",
              "18  I have a annotation json as my input, my acces...   \n",
              "\n",
              "                                             response  \n",
              "0   The MD.ai CLI is a command line interface tool...  \n",
              "1   MD.ai is a cloud platform for medical image an...  \n",
              "2                   I do not know the answer to that.  \n",
              "3                   I do not know the answer to that.  \n",
              "4   Yes, MD.ai supports de-id. It provides a suite...  \n",
              "5   To download MD.ai annotations, you can use the...  \n",
              "6   To perform segmentation on <some anatomical st...  \n",
              "7   Interpolation helps solve this problem by aski...  \n",
              "8   To render images from one plane to other plane...  \n",
              "9   To provide sub-classification on a label, you ...  \n",
              "10  There are a few reasons why you might not be a...  \n",
              "11  There are a few possible reasons why you might...  \n",
              "12  To get started, we recommend looking at severa...  \n",
              "13  MD.ai provides a suite of tools for all your d...  \n",
              "14  MD.ai cloud platform can help you speed up you...  \n",
              "15   MD.ai supports TensorFlow, PyTorch, and fast.ai.  \n",
              "16  To deploy a self-trained model on the MD.ai pl...  \n",
              "17  Teachers can use MD.ai cloud platform to creat...  \n",
              "18  Sure, here is a script that converts an annota...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-7c5ba213-2f6c-4208-ba2b-07c513924c65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is Md.ai command line interface tool?</td>\n",
              "      <td>The MD.ai CLI is a command line interface tool...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is Md.ai?</td>\n",
              "      <td>MD.ai is a cloud platform for medical image an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What should I have for dinner?</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Do you like dolphin?</td>\n",
              "      <td>I do not know the answer to that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does MD.ai support de-id?</td>\n",
              "      <td>Yes, MD.ai supports de-id. It provides a suite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Show me the example code to download MD.ai ann...</td>\n",
              "      <td>To download MD.ai annotations, you can use the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How can I perform segmentation on &lt;some anatom...</td>\n",
              "      <td>To perform segmentation on &lt;some anatomical st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How can I quickly segment &lt;some region of inte...</td>\n",
              "      <td>Interpolation helps solve this problem by aski...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Show me how to render images from one plane to...</td>\n",
              "      <td>To render images from one plane to other plane...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How would I provide sub-classification on a la...</td>\n",
              "      <td>To provide sub-classification on a label, you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Why can't I upload my data stored in Google cl...</td>\n",
              "      <td>There are a few reasons why you might not be a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Why can't I download the images in the dataset?</td>\n",
              "      <td>There are a few possible reasons why you might...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How should I start to annotate my medical images?</td>\n",
              "      <td>To get started, we recommend looking at severa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Will my patient data get leaked while using MD...</td>\n",
              "      <td>MD.ai provides a suite of tools for all your d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I am an admin staff working at a doctorâ€™s offi...</td>\n",
              "      <td>MD.ai cloud platform can help you speed up you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What deep learning models do MD.ai currently s...</td>\n",
              "      <td>MD.ai supports TensorFlow, PyTorch, and fast.ai.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How should I deploy a self-trained model? Is t...</td>\n",
              "      <td>To deploy a self-trained model on the MD.ai pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How could teachers use MD.ai cloud platform, a...</td>\n",
              "      <td>Teachers can use MD.ai cloud platform to creat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I have a annotation json as my input, my acces...</td>\n",
              "      <td>Sure, here is a script that converts an annota...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c5ba213-2f6c-4208-ba2b-07c513924c65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-ab0c4d59-368d-418b-abcf-45e166e25105\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab0c4d59-368d-418b-abcf-45e166e25105')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-ab0c4d59-368d-418b-abcf-45e166e25105 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c5ba213-2f6c-4208-ba2b-07c513924c65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c5ba213-2f6c-4208-ba2b-07c513924c65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 88
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No charts were generated by quickchart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"what is the code to export annotations into DICOM SR format?\")"
      ],
      "metadata": {
        "id": "uxh7LOC9jLLu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9daef62-d789-4196-ef95-2b3e3c4db074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Waiting\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSYSTEM: You are an intelligent assistant helping the users with their questions on techniques related to md.ai cloud platform products.\n",
            "\n",
            "Question: what is the code to export annotations into DICOM SR format?\n",
            "\n",
            "There is a set of rules:\n",
            "\n",
            "1. Use the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
            "\n",
            "2. If the answer is about coding, please make sure it is easy to separate text and code.\n",
            "\n",
            "3. If there are parts that the context does not answer, and it is about coding, you can use your coding knowledge.\n",
            "\n",
            "4. If the context has a link, always directly include the link in the response\n",
            "\n",
            "5. But for conceptual questions, Do not try to make up an answer and strictly answer based on the context.\n",
            "\n",
            "6. If the context is empty, just say \"I do not know the answer to that.\"\n",
            "\n",
            "\n",
            "=============\n",
            "## MD.AI Annotation to SR Export Tool\n",
            "### Export Annotations from MD.AI's platform into DICOM SR Format\n",
            "\n",
            "Some MD.ai packeges and some other Python packages need to be inputted. And then there is the of class \"SR_SEG_Export\". You need to have this class to be in a python file that can be accessed from your envionrment. You could then use this class to finish exporting annotation to DICOM SR format. The SR_SEG_Export class could also be found in this notebook: https://colab.research.google.com/drive/1d4I7wZhlRIS2T0nFo6dhmefi5qDHBSkW?usp=sharing\n",
            "\n",
            "```python\n",
            "import mdai.SR_SEG_Export\n",
            "\n",
            "mdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\n",
            "  annotation_json = 'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json',\n",
            "  metadata_json = 'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json'\n",
            ")\n",
            "\n",
            "```\n",
            "\n",
            "\n",
            "```python\n",
            "import mdai\n",
            "import pandas as pd\n",
            "from datetime import datetime\n",
            "import os\n",
            "import requests\n",
            "\n",
            "```py\n",
            "def convert_mha_file(\n",
            "    filepath,\n",
            "    output_dir='./processed_images',\n",
            "    plane=\"axial\",\n",
            "    sample_dicom_fp='./sample_dicom.dcm',\n",
            "    window_center=400,\n",
            "    window_width=1000\n",
            "):\n",
            "    \"\"\"Takes path to an mha file converts and saves as series of dicom files.\n",
            "    filepath: str path to an mha file.\n",
            "    output_dir:str root directory where images should be stored.\n",
            "    plane: Acquisition plane  of the original image.\n",
            "    sample_dicom_fp: Path to dicom image to use as reference\n",
            "    window_center: Dicom Parameter  used for windowing\n",
            "    window_width: Dicom Parameter used for windowing\n",
            "    \"\"\"\n",
            "    input_ext = '.mha'\n",
            "    voxel_arr,header = load(filepath)\n",
            "\n",
            "```\n",
            "\n",
            "Convert Freeform Annotations to DICOM SEG\n",
            "\n",
            "Instructions can be found here.\n",
            "\n",
            "Support functions\n",
            "\n",
            "Read DICOM UIDs and tags from your original files\n",
            "\n",
            "Use this code on your original data to create a dataframe of DICOM tags. These are sample tags, you can add or remove values, as needed.\n",
            "\n",
            "```py\n",
            "from pathlib import Path\n",
            "import pydicom\n",
            "\n",
            "Example output\n",
            "\n",
            "py\n",
            "Using working directory for data.\n",
            "Preparing annotations export for project MwBe19Br...\n",
            "Success: annotations data for project MwBe19Br ready.\n",
            "Downloading file: mdai_public_project_MwBe19Br_annotations_labelgroup_all_2020-09-23-214038.json\n",
            "No project created. Downloaded annotations only.\n",
            "\n",
            "Download model outputs\n",
            "\n",
            "```py\n",
            "\n",
            "Download only the model outputs data\n",
            "\n",
            "p = mdai_client.download_model_outputs(PROJECT_ID, DATASET_ID, MODEL_ID, path='.')\n",
            "```\n",
            "\n",
            "Example output\n",
            "\n",
            "py\n",
            "Using working directory for model outputs.\n",
            "Preparing model-outputs export for project MwBe19Br...\n",
            "Success: model-outputs data for project MwBe19Br ready.\n",
            "Downloading file: mdai_public_project_MwBe19Br_model-outputs_2020-09-23-214038.json\n",
            "\n",
            "Download DICOM metadata\n",
            "\n",
            "You can download the DICOM metadata in either json or csv format.\n",
            "\n",
            "```py\n",
            "\n",
            "Download only the DICOM metadata\n",
            "\n",
            "p = mdai_client.download_dicom_metadata(PROJECT_ID, DATASET_ID, format =\"json\", path='.')\n",
            "```\n",
            "\n",
            "Example output\n",
            "\n",
            "Import the metadata annotations\n",
            "\n",
            "py\n",
            "mdai_client.import_annotations(metadata_annotations, project_id, dataset_id)\n",
            "\n",
            "Example output:\n",
            "\n",
            "Sublabels / child annotations\n",
            "\n",
            "To import annotations for labels with sublabels, we can specify the sublabels using the children field. Each item in children should follow the appropriate format of its label type (see \"Annotation format\" section above). Ensure the specified DICOM resource UIDs match up with the label scopes.\n",
            "\n",
            "The labelId of the children must be sublabels. In the following example, L_rEGG7E and L_mEzplA are sublabels of the label L_5AJeMN.\n",
            "\n",
            "# Helper functions to place DICOM tags into SR document Template\n",
            "    # ---------------------------------------------------\n",
            "    '''\n",
            "    > Iterates through a given sequence of tags from the standard DICOM heirarchy\n",
            "    > Checks if the tag exists in the current DICOM file's headers\n",
            "    >>  If it does then it adds the tag to the SR document dataset\n",
            "    > Recursively calls itself to add tags in sequences and\n",
            "    >>  Checks if a sequence contains all its required tags and adds them if so\n",
            "    > Returns the SR document dataset with all tags added\n",
            "    > If there were no tags added then returns False\n",
            "    '''\n",
            "    def place_tags(self, curr_dataset, curr_seq):\n",
            "      sequences = {}\n",
            "      added = False\n",
            "      # Iterate through sequence to add tags and find sequences\n",
            "      for keyword in curr_seq:\n",
            "        if keyword in self.dicom_tags:\n",
            "          curr_dataset = self.add_to_dataset(curr_dataset, keyword, self.dicom_tags[keyword], True)\n",
            "          added = True\n",
            "        if self.keyword_to_VR_map[keyword] == 'SQ':\n",
            "          sequences[keyword] = curr_seq[keyword]\n",
            "\n",
            "      # Iterate through sequences to add tags and recursively search within sequences for tags\n",
            "      for keyword in sequences:\n",
            "        if keyword == 'ContentSequence': # Skips ContentSequence since it's meant to contain the annotations data\n",
            "            continue\n",
            "        seq = sequences[keyword]\n",
            "        new_dataset = Dataset()\n",
            "        new_dataset = self.place_tags(new_dataset, seq)\n",
            "        if new_dataset:\n",
            "          if self.keyword_to_VR_map[keyword] == 'SQ':\n",
            "            new_dataset = [new_dataset] # Pydicom requires sequences to be in a list\n",
            "          if self.check_required(new_dataset, seq):\n",
            "            added = True\n",
            "            curr_dataset = self.add_to_dataset(curr_dataset, keyword, new_dataset, True)\n",
            "\n",
            "      if added:\n",
            "        return curr_dataset\n",
            "\n",
            "      return False\n",
            "\n",
            "    # Checks if a sequence contains all its required tags\n",
            "    def check_required(self, curr_dataset, curr_seq):\n",
            "      for keyword in curr_seq:\n",
            "        tag_type = self.keyword_to_type_map[keyword]\n",
            "        if keyword not in curr_dataset and '1' == tag_type:\n",
            "          return False\n",
            "      return True\n",
            "\n",
            "    # Adds tag to dataset and if the tag already exists then\n",
            "    # Replaces tag if replace=True if not then does nothing\n",
            "    def add_to_dataset(self, dataset, keyword, value, replace):\n",
            "      VR = self.keyword_to_VR_map[keyword]\n",
            "\n",
            "      # If the tag is a sequence then the value in dicom_tags will be a list containing dictionary so need to convert to sequence format\n",
            "      if type(value) == list and VR == 'SQ':\n",
            "        if type(value[0]) == dict:\n",
            "          value = self.dict_to_sequence(value)\n",
            "\n",
            "      # If the tag is a byte encoding then need to switch it to so from string\n",
            "      if self.typos[VR] == bytes and value != None:\n",
            "        value = value[2:-1].encode('UTF-8') # removes b' and '\n",
            "\n",
            "      # If the tag is an int/float encoding then need to switch it to so from string\n",
            "      if self.typos[VR] == int or self.typos[VR] == float:\n",
            "        if value != None:\n",
            "          value = self.typos[VR](value)\n",
            "\n",
            "      # check if tag already in dataset\n",
            "      if keyword in dataset:\n",
            "        if not replace:\n",
            "          return dataset\n",
            "        dataset[keyword].value = value\n",
            "        return dataset\n",
            "\n",
            "      if 'or SS' in VR and type(value) == int: # Fix bug when VR == 'US or SS' and the value is negative (it always defaults to US)\n",
            "        if value < 0:\n",
            "          VR = 'SS'\n",
            "\n",
            "      dataset.add_new(keyword, VR, value)\n",
            "      return dataset\n",
            "\n",
            "    # Creates a sequence from a list of dictionaries\n",
            "    def dict_to_sequence(self, dict_seq_list):\n",
            "      sequences = []\n",
            "      for dict_seq in dict_seq_list:\n",
            "        seq = Dataset()\n",
            "        for keyword in dict_seq:\n",
            "          if self.keyword_to_VR_map[keyword] == 'SQ':\n",
            "            inner_seq = self.dict_to_sequence(dict_seq[keyword])\n",
            "            seq = self.add_to_dataset(seq, keyword, inner_seq, True)\n",
            "          else:\n",
            "            seq = self.add_to_dataset(seq, keyword, dict_seq[keyword], True)\n",
            "        sequences.append(seq)\n",
            "      return sequences\n",
            "\n",
            "    def create_exports(self):\n",
            "      # Iterate through each study and create SR document for each annotator in each study\n",
            "      # Save output to Output folder\n",
            "      # ---------------------------------------------------\n",
            "      try:\n",
            "        os.mkdir('Output')\n",
            "      except:\n",
            "        pass\n",
            "\n",
            "      from io import BytesIO\n",
            "      document_file = requests.get('https://github.com/spike-h/SRDocs/raw/main/Simple%20SR%20-%20RSNA.dcm')\n",
            "\n",
            "      for study_uid in self.studies:\n",
            "        #load file template\n",
            "        ds = dcmread(BytesIO(document_file.content))\n",
            "\n",
            "        self.dicom_tags = self.tags_df[self.tags_df.StudyInstanceUID == study_uid].dicomTags.values[0]\n",
            "        annotations = self.annots_df[self.annots_df.StudyInstanceUID == study_uid]\n",
            "        annotators = annotations.createdById.unique()\n",
            "        series_uid = pydicom.uid.generate_uid(prefix=None)\n",
            "        instance_uid = pydicom.uid.generate_uid(prefix=None)\n",
            "        date = datetime.now().strftime('%Y%m%d')\n",
            "        time = datetime.now().strftime('%H%M%S')\n",
            "\n",
            "        # Place all the tags from the dicom into the SR document\n",
            "        ds = self.place_tags(ds, self.dicom_tag_heirarchy)\n",
            "\n",
            "        # modify file metadata\n",
            "        ds.file_meta.MediaStorageSOPInstanceUID = instance_uid                              # Media Storage SOP Instance UID\n",
            "        ds.file_meta.ImplementationClassUID = str(pydicom.uid.PYDICOM_IMPLEMENTATION_UID)   # Implementation Class UID\n",
            "        ds.file_meta.ImplementationVersionName = str(pydicom.__version__)                   # Implementation Version Name\n",
            "\n",
            "        # delete tags\n",
            "        del ds[0x00080012]  # Instance Creation Date\n",
            "        del ds[0x00080013]  # Instance Creation Time\n",
            "        del ds[0x00080014]  # Instance Creator UID\n",
            "        # del ds[0x00100030]  # Patient's Birth Date\n",
            "\n",
            "        # modify tags\n",
            "        #-------------------------\n",
            "\n",
            "        ds['SOPClassUID'].value = '1.2.840.10008.5.1.4.1.1.88.22' # SOP Class UID = enhanced SR storage\n",
            "        ds[0x00080018].value = instance_uid  # SOPInstanceUID\n",
            "        ds[0x0008103e].value = str(self.metadata['name'].values[0])  # Series Description\n",
            "        ds[0x00080021].value = str(date)  # Series Date\n",
            "        ds[0x00080023].value = str(date)  # Content Date\n",
            "        ds[0x00080031].value = str(time)  # Series Time\n",
            "        ds[0x00080033].value = str(time)  # Content Time\n",
            "\n",
            "        ds[0x00181020].value = ''   # Software Versions\n",
            "\n",
            "        ds[0x0020000d].value = str(study_uid)   # Study Instance UID\n",
            "        ds[0x0020000e].value = str(series_uid)   # Series Instance UID\n",
            "        ds[0x00200011].value = str(1)           # Series Number\n",
            "=============\n",
            "\n",
            "Question: what is the code to export annotations into DICOM SR format?\n",
            "Helpful Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'what is the code to export annotations into DICOM SR format?', 'result': \"The code to export annotations into DICOM SR format is as follows:\\n\\n```python\\nimport mdai.SR_SEG_Export\\n\\nmdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\\n  annotation_json = 'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json',\\n  metadata_json = 'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json'\\n)\\n```\", 'source_documents': [Document(page_content='## MD.AI Annotation to SR Export Tool\\n### Export Annotations from MD.AI\\'s platform into DICOM SR Format\\n\\nSome MD.ai packeges and some other Python packages need to be inputted. And then there is the of class \"SR_SEG_Export\". You need to have this class to be in a python file that can be accessed from your envionrment. You could then use this class to finish exporting annotation to DICOM SR format. The SR_SEG_Export class could also be found in this notebook: https://colab.research.google.com/drive/1d4I7wZhlRIS2T0nFo6dhmefi5qDHBSkW?usp=sharing\\n\\n```python\\nimport mdai.SR_SEG_Export\\n\\nmdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\\n  annotation_json = \\'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json\\',\\n  metadata_json = \\'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json\\'\\n)\\n\\n```\\n\\n\\n```python\\nimport mdai\\nimport pandas as pd\\nfrom datetime import datetime\\nimport os\\nimport requests', metadata={'source': 'DICOM_SR_EXPORT', 'document_name': 'DICOM_SR_SEG.md', 'chunk': '0', 'score': 0.7954725027084351}), Document(page_content='```py\\ndef convert_mha_file(\\n    filepath,\\n    output_dir=\\'./processed_images\\',\\n    plane=\"axial\",\\n    sample_dicom_fp=\\'./sample_dicom.dcm\\',\\n    window_center=400,\\n    window_width=1000\\n):\\n    \"\"\"Takes path to an mha file converts and saves as series of dicom files.\\n    filepath: str path to an mha file.\\n    output_dir:str root directory where images should be stored.\\n    plane: Acquisition plane  of the original image.\\n    sample_dicom_fp: Path to dicom image to use as reference\\n    window_center: Dicom Parameter  used for windowing\\n    window_width: Dicom Parameter used for windowing\\n    \"\"\"\\n    input_ext = \\'.mha\\'\\n    voxel_arr,header = load(filepath)\\n\\n```\\n\\nConvert Freeform Annotations to DICOM SEG\\n\\nInstructions can be found here.\\n\\nSupport functions\\n\\nRead DICOM UIDs and tags from your original files\\n\\nUse this code on your original data to create a dataframe of DICOM tags. These are sample tags, you can add or remove values, as needed.\\n\\n```py\\nfrom pathlib import Path\\nimport pydicom', metadata={'source': '/content/gcs-store/docs/content/libraries/python', 'document_name': 'guides-convert-dcm.md', 'chunk': '129', 'score': 0.7799321413040161}), Document(page_content='Example output\\n\\npy\\nUsing working directory for data.\\nPreparing annotations export for project MwBe19Br...\\nSuccess: annotations data for project MwBe19Br ready.\\nDownloading file: mdai_public_project_MwBe19Br_annotations_labelgroup_all_2020-09-23-214038.json\\nNo project created. Downloaded annotations only.\\n\\nDownload model outputs\\n\\n```py\\n\\nDownload only the model outputs data\\n\\np = mdai_client.download_model_outputs(PROJECT_ID, DATASET_ID, MODEL_ID, path=\\'.\\')\\n```\\n\\nExample output\\n\\npy\\nUsing working directory for model outputs.\\nPreparing model-outputs export for project MwBe19Br...\\nSuccess: model-outputs data for project MwBe19Br ready.\\nDownloading file: mdai_public_project_MwBe19Br_model-outputs_2020-09-23-214038.json\\n\\nDownload DICOM metadata\\n\\nYou can download the DICOM metadata in either json or csv format.\\n\\n```py\\n\\nDownload only the DICOM metadata\\n\\np = mdai_client.download_dicom_metadata(PROJECT_ID, DATASET_ID, format =\"json\", path=\\'.\\')\\n```\\n\\nExample output', metadata={'source': '/content/gcs-store/docs/content/libraries/python', 'document_name': 'guides.md', 'chunk': '153', 'score': 0.7682688236236572}), Document(page_content='Import the metadata annotations\\n\\npy\\nmdai_client.import_annotations(metadata_annotations, project_id, dataset_id)\\n\\nExample output:\\n\\nSublabels / child annotations\\n\\nTo import annotations for labels with sublabels, we can specify the sublabels using the children field. Each item in children should follow the appropriate format of its label type (see \"Annotation format\" section above). Ensure the specified DICOM resource UIDs match up with the label scopes.\\n\\nThe labelId of the children must be sublabels. In the following example, L_rEGG7E and L_mEzplA are sublabels of the label L_5AJeMN.', metadata={'source': '/content/gcs-store/docs/content/libraries/python', 'document_name': 'guides-import.md', 'chunk': '149', 'score': 0.7651596069335938}), Document(page_content=\"# Helper functions to place DICOM tags into SR document Template\\n    # ---------------------------------------------------\\n    '''\\n    > Iterates through a given sequence of tags from the standard DICOM heirarchy\\n    > Checks if the tag exists in the current DICOM file's headers\\n    >>  If it does then it adds the tag to the SR document dataset\\n    > Recursively calls itself to add tags in sequences and\\n    >>  Checks if a sequence contains all its required tags and adds them if so\\n    > Returns the SR document dataset with all tags added\\n    > If there were no tags added then returns False\\n    '''\\n    def place_tags(self, curr_dataset, curr_seq):\\n      sequences = {}\\n      added = False\\n      # Iterate through sequence to add tags and find sequences\\n      for keyword in curr_seq:\\n        if keyword in self.dicom_tags:\\n          curr_dataset = self.add_to_dataset(curr_dataset, keyword, self.dicom_tags[keyword], True)\\n          added = True\\n        if self.keyword_to_VR_map[keyword] == 'SQ':\\n          sequences[keyword] = curr_seq[keyword]\\n\\n      # Iterate through sequences to add tags and recursively search within sequences for tags\\n      for keyword in sequences:\\n        if keyword == 'ContentSequence': # Skips ContentSequence since it's meant to contain the annotations data\\n            continue\\n        seq = sequences[keyword]\\n        new_dataset = Dataset()\\n        new_dataset = self.place_tags(new_dataset, seq)\\n        if new_dataset:\\n          if self.keyword_to_VR_map[keyword] == 'SQ':\\n            new_dataset = [new_dataset] # Pydicom requires sequences to be in a list\\n          if self.check_required(new_dataset, seq):\\n            added = True\\n            curr_dataset = self.add_to_dataset(curr_dataset, keyword, new_dataset, True)\\n\\n      if added:\\n        return curr_dataset\\n\\n      return False\\n\\n    # Checks if a sequence contains all its required tags\\n    def check_required(self, curr_dataset, curr_seq):\\n      for keyword in curr_seq:\\n        tag_type = self.keyword_to_type_map[keyword]\\n        if keyword not in curr_dataset and '1' == tag_type:\\n          return False\\n      return True\\n\\n    # Adds tag to dataset and if the tag already exists then\\n    # Replaces tag if replace=True if not then does nothing\\n    def add_to_dataset(self, dataset, keyword, value, replace):\\n      VR = self.keyword_to_VR_map[keyword]\\n\\n      # If the tag is a sequence then the value in dicom_tags will be a list containing dictionary so need to convert to sequence format\\n      if type(value) == list and VR == 'SQ':\\n        if type(value[0]) == dict:\\n          value = self.dict_to_sequence(value)\\n\\n      # If the tag is a byte encoding then need to switch it to so from string\\n      if self.typos[VR] == bytes and value != None:\\n        value = value[2:-1].encode('UTF-8') # removes b' and '\\n\\n      # If the tag is an int/float encoding then need to switch it to so from string\\n      if self.typos[VR] == int or self.typos[VR] == float:\\n        if value != None:\\n          value = self.typos[VR](value)\\n\\n      # check if tag already in dataset\\n      if keyword in dataset:\\n        if not replace:\\n          return dataset\\n        dataset[keyword].value = value\\n        return dataset\\n\\n      if 'or SS' in VR and type(value) == int: # Fix bug when VR == 'US or SS' and the value is negative (it always defaults to US)\\n        if value < 0:\\n          VR = 'SS'\\n\\n      dataset.add_new(keyword, VR, value)\\n      return dataset\\n\\n    # Creates a sequence from a list of dictionaries\\n    def dict_to_sequence(self, dict_seq_list):\\n      sequences = []\\n      for dict_seq in dict_seq_list:\\n        seq = Dataset()\\n        for keyword in dict_seq:\\n          if self.keyword_to_VR_map[keyword] == 'SQ':\\n            inner_seq = self.dict_to_sequence(dict_seq[keyword])\\n            seq = self.add_to_dataset(seq, keyword, inner_seq, True)\\n          else:\\n            seq = self.add_to_dataset(seq, keyword, dict_seq[keyword], True)\\n        sequences.append(seq)\\n      return sequences\\n\\n    def create_exports(self):\\n      # Iterate through each study and create SR document for each annotator in each study\\n      # Save output to Output folder\\n      # ---------------------------------------------------\\n      try:\\n        os.mkdir('Output')\\n      except:\\n        pass\\n\\n      from io import BytesIO\\n      document_file = requests.get('https://github.com/spike-h/SRDocs/raw/main/Simple%20SR%20-%20RSNA.dcm')\\n\\n      for study_uid in self.studies:\\n        #load file template\\n        ds = dcmread(BytesIO(document_file.content))\\n\\n        self.dicom_tags = self.tags_df[self.tags_df.StudyInstanceUID == study_uid].dicomTags.values[0]\\n        annotations = self.annots_df[self.annots_df.StudyInstanceUID == study_uid]\\n        annotators = annotations.createdById.unique()\\n        series_uid = pydicom.uid.generate_uid(prefix=None)\\n        instance_uid = pydicom.uid.generate_uid(prefix=None)\\n        date = datetime.now().strftime('%Y%m%d')\\n        time = datetime.now().strftime('%H%M%S')\\n\\n        # Place all the tags from the dicom into the SR document\\n        ds = self.place_tags(ds, self.dicom_tag_heirarchy)\\n\\n        # modify file metadata\\n        ds.file_meta.MediaStorageSOPInstanceUID = instance_uid                              # Media Storage SOP Instance UID\\n        ds.file_meta.ImplementationClassUID = str(pydicom.uid.PYDICOM_IMPLEMENTATION_UID)   # Implementation Class UID\\n        ds.file_meta.ImplementationVersionName = str(pydicom.__version__)                   # Implementation Version Name\\n\\n        # delete tags\\n        del ds[0x00080012]  # Instance Creation Date\\n        del ds[0x00080013]  # Instance Creation Time\\n        del ds[0x00080014]  # Instance Creator UID\\n        # del ds[0x00100030]  # Patient's Birth Date\\n\\n        # modify tags\\n        #-------------------------\\n\\n        ds['SOPClassUID'].value = '1.2.840.10008.5.1.4.1.1.88.22' # SOP Class UID = enhanced SR storage\\n        ds[0x00080018].value = instance_uid  # SOPInstanceUID\\n        ds[0x0008103e].value = str(self.metadata['name'].values[0])  # Series Description\\n        ds[0x00080021].value = str(date)  # Series Date\\n        ds[0x00080023].value = str(date)  # Content Date\\n        ds[0x00080031].value = str(time)  # Series Time\\n        ds[0x00080033].value = str(time)  # Content Time\\n\\n        ds[0x00181020].value = ''   # Software Versions\\n\\n        ds[0x0020000d].value = str(study_uid)   # Study Instance UID\\n        ds[0x0020000e].value = str(series_uid)   # Series Instance UID\\n        ds[0x00200011].value = str(1)           # Series Number\", metadata={'source': 'DICOM_SR_EXPORT', 'document_name': 'DICOM_SR_SEG.md', 'chunk': '1', 'score': 0.7631246447563171})]}\n",
            "Query: what is the code to export annotations into DICOM SR format?\n",
            "................................................................................\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #0\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7954725027084351\n",
            "Document Source: DICOM_SR_EXPORT\n",
            "Document Name: DICOM_SR_SEG.md\n",
            "................................................................................\n",
            "Content: \n",
            "## MD.AI Annotation to SR Export Tool ### Export Annotations from MD.AI's platform into DICOM SR Format  Some MD.ai\n",
            "packeges and some other Python packages need to be inputted. And then there is the of class \"SR_SEG_Export\". You need to\n",
            "have this class to be in a python file that can be accessed from your envionrment. You could then use this class to\n",
            "finish exporting annotation to DICOM SR format. The SR_SEG_Export class could also be found in this notebook:\n",
            "https://colab.research.google.com/drive/1d4I7wZhlRIS2T0nFo6dhmefi5qDHBSkW?usp=sharing  ```python import\n",
            "mdai.SR_SEG_Export  mdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(   annotation_json =\n",
            "'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json',   metadata_json =\n",
            "'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json' )  ```   ```python import mdai import pandas as pd\n",
            "from datetime import datetime import os import requests\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #1\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7799321413040161\n",
            "Document Source: /content/gcs-store/docs/content/libraries/python\n",
            "Document Name: guides-convert-dcm.md\n",
            "................................................................................\n",
            "Content: \n",
            "```py def convert_mha_file(     filepath,     output_dir='./processed_images',     plane=\"axial\",\n",
            "sample_dicom_fp='./sample_dicom.dcm',     window_center=400,     window_width=1000 ):     \"\"\"Takes path to an mha file\n",
            "converts and saves as series of dicom files.     filepath: str path to an mha file.     output_dir:str root directory\n",
            "where images should be stored.     plane: Acquisition plane  of the original image.     sample_dicom_fp: Path to dicom\n",
            "image to use as reference     window_center: Dicom Parameter  used for windowing     window_width: Dicom Parameter used\n",
            "for windowing     \"\"\"     input_ext = '.mha'     voxel_arr,header = load(filepath)  ```  Convert Freeform Annotations to\n",
            "DICOM SEG  Instructions can be found here.  Support functions  Read DICOM UIDs and tags from your original files  Use\n",
            "this code on your original data to create a dataframe of DICOM tags. These are sample tags, you can add or remove\n",
            "values, as needed.  ```py from pathlib import Path import pydicom\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #2\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7682688236236572\n",
            "Document Source: /content/gcs-store/docs/content/libraries/python\n",
            "Document Name: guides.md\n",
            "................................................................................\n",
            "Content: \n",
            "Example output  py Using working directory for data. Preparing annotations export for project MwBe19Br... Success:\n",
            "annotations data for project MwBe19Br ready. Downloading file:\n",
            "mdai_public_project_MwBe19Br_annotations_labelgroup_all_2020-09-23-214038.json No project created. Downloaded\n",
            "annotations only.  Download model outputs  ```py  Download only the model outputs data  p =\n",
            "mdai_client.download_model_outputs(PROJECT_ID, DATASET_ID, MODEL_ID, path='.') ```  Example output  py Using working\n",
            "directory for model outputs. Preparing model-outputs export for project MwBe19Br... Success: model-outputs data for\n",
            "project MwBe19Br ready. Downloading file: mdai_public_project_MwBe19Br_model-outputs_2020-09-23-214038.json  Download\n",
            "DICOM metadata  You can download the DICOM metadata in either json or csv format.  ```py  Download only the DICOM\n",
            "metadata  p = mdai_client.download_dicom_metadata(PROJECT_ID, DATASET_ID, format =\"json\", path='.') ```  Example output\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #3\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7651596069335938\n",
            "Document Source: /content/gcs-store/docs/content/libraries/python\n",
            "Document Name: guides-import.md\n",
            "................................................................................\n",
            "Content: \n",
            "Import the metadata annotations  py mdai_client.import_annotations(metadata_annotations, project_id, dataset_id)\n",
            "Example output:  Sublabels / child annotations  To import annotations for labels with sublabels, we can specify the\n",
            "sublabels using the children field. Each item in children should follow the appropriate format of its label type (see\n",
            "\"Annotation format\" section above). Ensure the specified DICOM resource UIDs match up with the label scopes.  The\n",
            "labelId of the children must be sublabels. In the following example, L_rEGG7E and L_mEzplA are sublabels of the label\n",
            "L_5AJeMN.\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #4\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7631246447563171\n",
            "Document Source: DICOM_SR_EXPORT\n",
            "Document Name: DICOM_SR_SEG.md\n",
            "................................................................................\n",
            "Content: \n",
            "# Helper functions to place DICOM tags into SR document Template     #\n",
            "---------------------------------------------------     '''     > Iterates through a given sequence of tags from the\n",
            "standard DICOM heirarchy     > Checks if the tag exists in the current DICOM file's headers     >>  If it does then it\n",
            "adds the tag to the SR document dataset     > Recursively calls itself to add tags in sequences and     >>  Checks if a\n",
            "sequence contains all its required tags and adds them if so     > Returns the SR document dataset with all tags added\n",
            "> If there were no tags added then returns False     '''     def place_tags(self, curr_dataset, curr_seq):\n",
            "sequences = {}       added = False       # Iterate through sequence to add tags and find sequences       for keyword in\n",
            "curr_seq:         if keyword in self.dicom_tags:           curr_dataset = self.add_to_dataset(curr_dataset, keyword,\n",
            "self.dicom_tags[keyword], True)           added = True         if self.keyword_to_VR_map[keyword] == 'SQ':\n",
            "sequences[keyword] = curr_seq[keyword]        # Iterate through sequences to add tags and recursively search within\n",
            "sequences for tags       for keyword in sequences:         if keyword == 'ContentSequence': # Skips ContentSequence\n",
            "since it's meant to contain the annotations data             continue         seq = sequences[keyword]\n",
            "new_dataset = Dataset()         new_dataset = self.place_tags(new_dataset, seq)         if new_dataset:           if\n",
            "self.keyword_to_VR_map[keyword] == 'SQ':             new_dataset = [new_dataset] # Pydicom requires sequences to be in a\n",
            "list           if self.check_required(new_dataset, seq):             added = True             curr_dataset =\n",
            "self.add_to_dataset(curr_dataset, keyword, new_dataset, True)        if added:         return curr_dataset        return\n",
            "False      # Checks if a sequence contains all its required tags     def check_required(self, curr_dataset, curr_seq):\n",
            "for keyword in curr_seq:         tag_type = self.keyword_to_type_map[keyword]         if keyword not in curr_dataset and\n",
            "'1' == tag_type:           return False       return True      # Adds tag to dataset and if the tag already exists then\n",
            "# Replaces tag if replace=True if not then does nothing     def add_to_dataset(self, dataset, keyword, value, replace):\n",
            "VR = self.keyword_to_VR_map[keyword]        # If the tag is a sequence then the value in dicom_tags will be a list\n",
            "containing dictionary so need to convert to sequence format       if type(value) == list and VR == 'SQ':         if\n",
            "type(value[0]) == dict:           value = self.dict_to_sequence(value)        # If the tag is a byte encoding then need\n",
            "to switch it to so from string       if self.typos[VR] == bytes and value != None:         value =\n",
            "value[2:-1].encode('UTF-8') # removes b' and '        # If the tag is an int/float encoding then need to switch it to so\n",
            "from string       if self.typos[VR] == int or self.typos[VR] == float:         if value != None:           value =\n",
            "self.typos[VR](value)        # check if tag already in dataset       if keyword in dataset:         if not replace:\n",
            "return dataset         dataset[keyword].value = value         return dataset        if 'or SS' in VR and type(value) ==\n",
            "int: # Fix bug when VR == 'US or SS' and the value is negative (it always defaults to US)         if value < 0:\n",
            "VR = 'SS'        dataset.add_new(keyword, VR, value)       return dataset      # Creates a sequence from a list of\n",
            "dictionaries     def dict_to_sequence(self, dict_seq_list):       sequences = []       for dict_seq in dict_seq_list:\n",
            "seq = Dataset()         for keyword in dict_seq:           if self.keyword_to_VR_map[keyword] == 'SQ':\n",
            "inner_seq = self.dict_to_sequence(dict_seq[keyword])             seq = self.add_to_dataset(seq, keyword, inner_seq,\n",
            "True)           else:             seq = self.add_to_dataset(seq, keyword, dict_seq[keyword], True)\n",
            "sequences.append(seq)       return sequences      def create_exports(self):       # Iterate through each study and\n",
            "create SR document for each annotator in each study       # Save output to Output folder       #\n",
            "---------------------------------------------------       try:         os.mkdir('Output')       except:         pass\n",
            "from io import BytesIO       document_file =\n",
            "requests.get('https://github.com/spike-h/SRDocs/raw/main/Simple%20SR%20-%20RSNA.dcm')        for study_uid in\n",
            "self.studies:         #load file template         ds = dcmread(BytesIO(document_file.content))          self.dicom_tags\n",
            "= self.tags_df[self.tags_df.StudyInstanceUID == study_uid].dicomTags.values[0]         annotations =\n",
            "self.annots_df[self.annots_df.StudyInstanceUID == study_uid]         annotators = annotations.createdById.unique()\n",
            "series_uid = pydicom.uid.generate_uid(prefix=None)         instance_uid = pydicom.uid.generate_uid(prefix=None)\n",
            "date = datetime.now().strftime('%Y%m%d')         time = datetime.now().strftime('%H%M%S')          # Place all the tags\n",
            "from the dicom into the SR document         ds = self.place_tags(ds, self.dicom_tag_heirarchy)          # modify file\n",
            "metadata         ds.file_meta.MediaStorageSOPInstanceUID = instance_uid                              # Media Storage SOP\n",
            "Instance UID         ds.file_meta.ImplementationClassUID = str(pydicom.uid.PYDICOM_IMPLEMENTATION_UID)   #\n",
            "Implementation Class UID         ds.file_meta.ImplementationVersionName = str(pydicom.__version__)                   #\n",
            "Implementation Version Name          # delete tags         del ds[0x00080012]  # Instance Creation Date         del\n",
            "ds[0x00080013]  # Instance Creation Time         del ds[0x00080014]  # Instance Creator UID         # del ds[0x00100030]\n",
            "# Patient's Birth Date          # modify tags         #-------------------------          ds['SOPClassUID'].value =\n",
            "'1.2.840.10008.5.1.4.1.1.88.22' # SOP Class UID = enhanced SR storage         ds[0x00080018].value = instance_uid  #\n",
            "SOPInstanceUID         ds[0x0008103e].value = str(self.metadata['name'].values[0])  # Series Description\n",
            "ds[0x00080021].value = str(date)  # Series Date         ds[0x00080023].value = str(date)  # Content Date\n",
            "ds[0x00080031].value = str(time)  # Series Time         ds[0x00080033].value = str(time)  # Content Time\n",
            "ds[0x00181020].value = ''   # Software Versions          ds[0x0020000d].value = str(study_uid)   # Study Instance UID\n",
            "ds[0x0020000e].value = str(series_uid)   # Series Instance UID         ds[0x00200011].value = str(1)           # Series\n",
            "Number\n",
            "................................................................................\n",
            "Response: The code to export annotations into DICOM SR format is as follows:  ```python import mdai.SR_SEG_Export\n",
            "mdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(   annotation_json =\n",
            "'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json',   metadata_json =\n",
            "'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json' ) ```\n",
            "................................................................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The code to export annotations into DICOM SR format is as follows:  ```python import mdai.SR_SEG_Export\\nmdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(   annotation_json =\\n'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json',   metadata_json =\\n'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json' ) ```\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"what is the code to export annotations into DICOM SR format?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NEl5suVUGyUN",
        "outputId": "6df0b990-c44e-4859-a529-d6a394a35df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Waiting\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSYSTEM: You are an intelligent assistant helping the users with their questions on techniques related to md.ai cloud platform products.\n",
            "\n",
            "Question: what is the code to export annotations into DICOM SR format?\n",
            "\n",
            "There is a set of rules: \n",
            "\n",
            "1. Use the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
            "\n",
            "2. If the answer is about coding, please make sure it is easy to separate text and code.\n",
            "\n",
            "3. If there are parts that the context does not answer, and it is about coding, you can use your coding knowledge.\n",
            "\n",
            "4. If the context has a link, always directly include the link in the response\n",
            "\n",
            "5. But for conceptual questions, Do not try to make up an answer and strictly answer based on the context.\n",
            "\n",
            "6. If the context is empty, just say \"I do not know the answer to that.\"\n",
            "\n",
            "\n",
            "=============\n",
            "## MD.AI Annotation to SR Export Tool\n",
            "### Export Annotations from MD.AI's platform into DICOM SR Format\n",
            "\n",
            "Some MD.ai packeges and some other Python packages need to be inputted. And then there is the of class \"SR_SEG_Export\". You need to have this class to be in a python file that can be accessed from your envionrment. You could then use this class to finish exporting annotation to DICOM SR format. The SR_SEG_Export class could also be found in this notebook: https://colab.research.google.com/drive/1d4I7wZhlRIS2T0nFo6dhmefi5qDHBSkW?usp=sharing\n",
            "\n",
            "```python\n",
            "import mdai.SR_SEG_Export\n",
            "\n",
            "mdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\n",
            "  annotation_json = 'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json',\n",
            "  metadata_json = 'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json'\n",
            ")\n",
            "\n",
            "```\n",
            "\n",
            "\n",
            "```python\n",
            "import mdai\n",
            "import pandas as pd\n",
            "from datetime import datetime\n",
            "import os\n",
            "import requests\n",
            "=============\n",
            "\n",
            "Question: what is the code to export annotations into DICOM SR format?\n",
            "Helpful Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'what is the code to export annotations into DICOM SR format?', 'result': \"To export annotations into DICOM SR format, you can use the following code:\\n\\n```python\\nimport mdai.SR_SEG_Export\\n\\nmdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\\n  annotation_json = 'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json',\\n  metadata_json = 'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json'\\n)\\n```\\n\\nThis code will export the annotations in the specified JSON files into DICOM SR format.\", 'source_documents': [Document(page_content='## MD.AI Annotation to SR Export Tool\\n### Export Annotations from MD.AI\\'s platform into DICOM SR Format\\n\\nSome MD.ai packeges and some other Python packages need to be inputted. And then there is the of class \"SR_SEG_Export\". You need to have this class to be in a python file that can be accessed from your envionrment. You could then use this class to finish exporting annotation to DICOM SR format. The SR_SEG_Export class could also be found in this notebook: https://colab.research.google.com/drive/1d4I7wZhlRIS2T0nFo6dhmefi5qDHBSkW?usp=sharing\\n\\n```python\\nimport mdai.SR_SEG_Export\\n\\nmdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(\\n  annotation_json = \\'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json\\',\\n  metadata_json = \\'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json\\'\\n)\\n\\n```\\n\\n\\n```python\\nimport mdai\\nimport pandas as pd\\nfrom datetime import datetime\\nimport os\\nimport requests', metadata={'source': 'DICOM_SR_EXPORT', 'document_name': 'DICOM_SR_SEG.md', 'chunk': '0', 'score': 0.7954725027084351})]}\n",
            "Query: what is the code to export annotations into DICOM SR format?\n",
            "................................................................................\n",
            "--------------------------------------------------------------------------------\n",
            "REFERENCE #0\n",
            "--------------------------------------------------------------------------------\n",
            "Matching Score: 0.7954725027084351\n",
            "Document Source: DICOM_SR_EXPORT\n",
            "Document Name: DICOM_SR_SEG.md\n",
            "................................................................................\n",
            "Content: \n",
            "## MD.AI Annotation to SR Export Tool ### Export Annotations from MD.AI's platform into DICOM SR Format  Some MD.ai\n",
            "packeges and some other Python packages need to be inputted. And then there is the of class \"SR_SEG_Export\". You need to\n",
            "have this class to be in a python file that can be accessed from your envionrment. You could then use this class to\n",
            "finish exporting annotation to DICOM SR format. The SR_SEG_Export class could also be found in this notebook:\n",
            "https://colab.research.google.com/drive/1d4I7wZhlRIS2T0nFo6dhmefi5qDHBSkW?usp=sharing  ```python import\n",
            "mdai.SR_SEG_Export  mdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(   annotation_json =\n",
            "'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json',   metadata_json =\n",
            "'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json' )  ```   ```python import mdai import pandas as pd\n",
            "from datetime import datetime import os import requests\n",
            "................................................................................\n",
            "Response: To export annotations into DICOM SR format, you can use the following code:  ```python import mdai.SR_SEG_Export\n",
            "mdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(   annotation_json =\n",
            "'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json',   metadata_json =\n",
            "'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json' ) ```  This code will export the annotations in the\n",
            "specified JSON files into DICOM SR format.\n",
            "................................................................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"To export annotations into DICOM SR format, you can use the following code:  ```python import mdai.SR_SEG_Export\\nmdai.SR_SEG_EXPORT.SR_SEG_EXPORT.SR_Export(   annotation_json =\\n'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-135404.json',   metadata_json =\\n'mdai_staging_project_L1NpnQBv_annotations_2023-06-28-165932.json' ) ```  This code will export the annotations in the\\nspecified JSON files into DICOM SR format.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gcloud ai indexes list --project=\"mdai-interns-summer-2023\" --region=\"us-central1\""
      ],
      "metadata": {
        "id": "clV6ms7XrwG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is the part that deletes and undeploy index, be careful when running it"
      ],
      "metadata": {
        "id": "wCB0_p1XA3Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleanup\n",
        "CLEANUP_RESOURCES = True"
      ],
      "metadata": {
        "id": "1Y4pUPRCPSNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ME_INDEX_ID, ME_INDEX_ENDPOINT_ID = mengine.get_index_and_endpoint()\n",
        "print(f\"ME_INDEX_ID={ME_INDEX_ID}\")\n",
        "print(f\"ME_INDEX_ENDPOINT_ID={ME_INDEX_ENDPOINT_ID}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rMPXJKkQBY6",
        "outputId": "c80a7a0b-d6c3-4a56-923b-a071ccf331c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ME_INDEX_ID=projects/837432346917/locations/us-central1/indexes/5471935119906308096\n",
            "ME_INDEX_ENDPOINT_ID=projects/837432346917/locations/us-central1/indexEndpoints/3505550932605665280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# undeploy\n",
        "if CLEANUP_RESOURCES and \"mengine\" in globals():\n",
        "    print(\n",
        "        f\"Undeploying all indexes and deleting the index endpoint {ME_INDEX_ENDPOINT_ID}\"\n",
        "    )\n",
        "    mengine.delete_index_endpoint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX5YusheQCoR",
        "outputId": "f77c23cb-69a0-403d-a79e-04ad22a57efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undeploying all indexes and deleting the index endpoint projects/837432346917/locations/us-central1/indexEndpoints/3505550932605665280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete\n",
        "if CLEANUP_RESOURCES and \"mengine\" in globals():\n",
        "    print(f\"Deleting the index {ME_INDEX_ID}\")\n",
        "    mengine.delete_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh8J16uUQIUH",
        "outputId": "c81fe963-d52e-4899-cfa4-5766ce66fbb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting the index projects/837432346917/locations/us-central1/indexes/5471935119906308096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if CLEANUP_RESOURCES and \"ME_EMBEDDING_DIR\" in globals():\n",
        "    print(f\"Deleting contents from the Cloud Storage bucket {ME_EMBEDDING_DIR}\")\n",
        "    ME_EMBEDDING_BUCKET = \"/\".join(ME_EMBEDDING_DIR.split(\"/\")[:3])\n",
        "\n",
        "    shell_output = ! gsutil du -ash $ME_EMBEDDING_BUCKET\n",
        "    print(\n",
        "        f\"Size of the bucket {ME_EMBEDDING_BUCKET} before deleting = {' '.join(shell_output[0].split()[:2])}\"\n",
        "    )\n",
        "\n",
        "    # uncomment below line to delete contents of the bucket\n",
        "    ! gsutil rm -r $ME_EMBEDDING_BUCKET\n",
        "\n",
        "    shell_output = ! gsutil du -ash $ME_EMBEDDING_BUCKET\n",
        "    if float(shell_output[0].split()[0]) > 0:\n",
        "        print(\n",
        "            \"PLEASE UNCOMMENT LINE TO DELETE BUCKET. CONTENT FROM THE BUCKET NOT DELETED\"\n",
        "        )\n",
        "\n",
        "    print(\n",
        "        f\"Size of the bucket {ME_EMBEDDING_BUCKET} after deleting = {' '.join(shell_output[0].split()[:2])}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "OjSyjQ42QpAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! gcloud ai indexes list --project=\"mdai-interns-summer-2023\" --region=\"us-central1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PScZ6_WQsY8",
        "outputId": "d4e869a0-d142-436d-b5d5-d259a384edfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Listed 0 items.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "il4hzHgcB7le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information Summarization"
      ],
      "metadata": {
        "id": "ymqBT8LLj0V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize mdai client with necessary identification information\n",
        "%%capture\n",
        "! pip install --upgrade mdai\n",
        "\n",
        "import mdai\n",
        "import json\n",
        "domain = # your domain\n",
        "access_token = # your access token\n",
        "mdai_client = mdai.Client(domain= domain, access_token= access_token)"
      ],
      "metadata": {
        "id": "9oZOzq0qlukB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. Use the following pieces of context to answer the question at the end. Think step-by-step and then answer.\n",
        "\n",
        "2. If the answer is about coding, please make sure it is easy to separate text and code.\n",
        "\n",
        "3. If there are parts that the context does not answer, and it is about coding, you can use your coding knowledge.\n",
        "\n",
        "4. If the context has a link, always directly include the link in the response\n",
        "\n",
        "5. But for conceptual questions, Do not try to make up an answer and strictly answer based on the context.\n",
        "\n",
        "6. If the context is empty, just say \"I do not know the answer to that.\"\n",
        "\"\"\"\n",
        "\n",
        "context = [\"project_id = x9N2KMqZ\"]\n",
        "system_prompt = \"\"\"You are a bot helping give summary information based on context.\n",
        "\n",
        "There is a set of rules:\n",
        "\n",
        "=============\n",
        "{context}\n",
        "=============\n",
        "\n",
        "\"\"\"\n",
        "formatted_context = system_prompt.format(context='\\n'.join(context))\n",
        "formatted_context\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "F758AHQtkACt",
        "outputId": "196a104e-ff71-49af-c4bd-e1cade126f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are a bot helping give summary information based on context. \\n\\nThere is a set of rules: \\n\\n=============\\nproject_id = x9N2KMqZ\\n=============\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"what is my project id?\"\n",
        "messages = [ {\"role\": \"system\", \"content\": formatted_context},\n",
        "          {\"role\": \"user\", \"content\": prompt}]\n",
        "result = mdai_client.chat_completion.create(messages, model='gpt-3.5-turbo', temperature=0)\n",
        "result[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MMqqzYZblUGg",
        "outputId": "abbdafcb-f55c-4b07-eee3-e4d159a96896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but as a language model AI, I don't have access to personal information or the ability to retrieve your project ID. Please check with the relevant platform or service you are using to find your project ID.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"what is my project id?\"\n",
        "messages = [ {\"role\": \"system\", \"content\": formatted_context},\n",
        "          {\"role\": \"user\", \"content\": prompt}]\n",
        "result = mdai_client.chat_completion.create(messages, model='gpt-4', temperature=0)\n",
        "result[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E_gS0BasmoPH",
        "outputId": "7b9c60f7-4389-413e-a81a-ad10f386c13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your project ID is x9N2KMqZ.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aL1yl9DXnZ7C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}