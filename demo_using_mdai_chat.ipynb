{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-BV3VbtadNP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install --upgrade mdai\n",
        "\n",
        "import mdai\n",
        "import json\n",
        "domain = # your domain, e.g. public.md.ai or staging.md.ai\n",
        "access_token = # your external access token\n",
        "mdai_client = mdai.Client(domain= domain, access_token= access_token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to transform a markdown format file to txt plan text,\n",
        "# pure text might be better for LLM to understand (no need to deal with weird\n",
        "# markdown syntax)\n",
        "\n",
        "import markdown\n",
        "import re\n",
        "\n",
        "def convert_markdown_to_text(markdown_file):\n",
        "    with open(markdown_file, 'r') as file:\n",
        "        markdown_text = file.read()\n",
        "\n",
        "    # Convert Markdown to HTML\n",
        "    html = markdown.markdown(markdown_text)\n",
        "\n",
        "    # Remove HTML tags\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    plain_text = re.sub(cleanr, '', html)\n",
        "\n",
        "    # Remove Markdown syntax\n",
        "    plain_text = re.sub(r'(\\*\\*|__)(.*?)\\1', r'\\2', plain_text)  # Remove bold text\n",
        "    plain_text = re.sub(r'(\\*|_)(.*?)\\1', r'\\2', plain_text)    # Remove italic text\n",
        "    plain_text = re.sub(r'\\[(.*?)\\]\\((.*?)\\)', r'\\1 (\\2)', plain_text)  # Convert links to plain text format\n",
        "    plain_text = re.sub(r'^\\s*#(.*?)$', r'\\1', plain_text, flags=re.MULTILINE)  # Remove headings\n",
        "\n",
        "    # Remove leading/trailing whitespaces\n",
        "    plain_text = plain_text.strip()\n",
        "    return plain_text\n"
      ],
      "metadata": {
        "id": "oGNYCpE4Os_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gpt_response_generation(user_content_p1, system_content_p2, markdown_file):\n",
        "  text_data = convert_markdown_to_text(markdown_file)\n",
        "  knowledge_base = \"You can extract the answer from here: but be careful the code that involves == is replaced with = =, so if you want to show code as your answer, please make sure you present as == not = =, also \\\n",
        "  remember that a lot of the knowledge back involve backslash n because it's the code interpretion, you should think of it just as to the next line \\\n",
        "  and backslash quotation mark is just quotation mark, if the question is about code, try give as much as you can, if it is not asking for code, you could keep your conceptual response simple and straightforward, \\\n",
        "  but do not forget to make your response on point, make sure there is no extra code or comment that goes beyond what the question asks\" + text_data\n",
        "  user_content_p2 = user_content_p1 + \"\\n\" + knowledge_base\n",
        "\n",
        "  # user_content_p2 = user_content_p2.replace(\"```python\", \"```txt\")\n",
        "  # user_content_p2 = user_content_p2.replace(\"`\", \" \")\n",
        "  # user_content_p2 = user_content_p2.replace(\" == \", \" = = \")\n",
        "  # user_content_p2 = user_content_p2.replace(\"/.bashrc\", \"/. bashrc\")\n",
        "  # user_content_p2 = user_content_p2.replace(\"&lt;\", \"<\")\n",
        "  # user_content_p2 = user_content_p2.replace(\"&gt;\", \">\")\n",
        "  # user_content_p2 = user_content_p2[:]\n",
        "\n",
        "  messages_p2 = [{\"role\": \"system\", \"content\": system_content_p2},\n",
        "            {\"role\": \"user\", \"content\": user_content_p2}]\n",
        "  # messages_p2 = [{\"role\": \"system\", \"content\": system_content_p2},\n",
        "  #           {\"role\": \"user\", \"content\": \"\"}]\n",
        "  result = mdai_client.chat_completion.create(messages_p2, model='gpt-3.5-turbo', temperature=0)\n",
        "  return result[\"choices\"][0][\"message\"][\"content\"]\n"
      ],
      "metadata": {
        "id": "mbjBnzOhxFuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_content_p1 = \"What are the three files that I could download to install MD.ai Command line interface\"\n",
        "system_content_p2 = \"You are a bot helping with answering a question according to a documentation page of a medicial AI website.\"\n",
        "markdown_file = '/content/installation.md'\n",
        "result = gpt_response_generation(user_content_p1, system_content_p2, markdown_file)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "qLmG86H6Rbo7",
        "outputId": "ca960c92-7496-49e8-8d17-b738841039a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are the three files that I could download to install MD.ai Command line interface\n",
            "You can extract the answer from here: but be careful the code that involves = = is replaced with = =, so if you want to show code as your answer, please make sure you present as = = not = =, also   remember that a lot of the knowledge back involve backslash n because it's the code interpretion, you should think of it just as to the next line   and backslash quotation mark is just quotation mark, if the question is about code, try give as much as you can, if it is not asking for code, you could keep your conceptual response simple and straightforward,   but do not forget to make your response on point, make sure there is no extra code or comment that goes beyond what the question asksInstalling the MD.ai Command-line Interface (CLI)\n",
            "The MD.ai CLI is a convenient tool for efficiently accessing a subset of the MD.ai API, such as creating new projects and datasets, uploading large files to project datasets, deleting datasets &amp; DICOM resources, and user management.\n",
            "!!! tip \"Download and install the latest version : v{{ LATEST_VERSION }}\"\n",
            "Download appropriate zip file containing the binary package for your platform. Note that only 64-bit platforms are supported.\n",
            "\n",
            "Windows (https://storage.googleapis.com/mdai-app-data/cli-releases/mdaicli{{ LATESTVERSION }}windows_amd64.zip) |\n",
            "MacOS (https://storage.googleapis.com/mdai-app-data/cli-releases/mdaicli{{ LATESTVERSION }}darwin_amd64.zip) |\n",
            "Linux (https://storage.googleapis.com/mdai-app-data/cli-releases/mdaicli{{ LATESTVERSION }}linux_amd64.zip)\n",
            "\n",
            "After downloading, unzip the package. To run the  mdai  binary from any directory, make sure that the binary is available on the  PATH . The following are instructions for on setting the  PATH \n",
            "\n",
            "- PATH instructions for Windows (https://stackoverflow.com/questions/1618280/where-can-i-set-path-to-make-exe-on-windows)\n",
            "- PATH instructions for Mac (https://www.architectryan.com/2012/10/02/add-to-the-path-on-mac-os-x-mountain-lion/)\n",
            "- PATH instructions for Linux (https://stackoverflow.com/questions/14637979/how-to-permanently-set-path-on-linux).\n",
            "\n",
            "!!! tip \"Automatic Updates\"\n",
            "With v0.19.0+, MD.ai CLI can be configured (../configuration#automatic-update) to automatically upgrade to the latest version.\n",
            "\n",
            "Verifying the Installation\n",
            "After installing, verify the installation by starting a new terminal session and running mdai. By executing mdai you should see help output similar to this:\n",
            "   text\n",
            "$ mdai\n",
            "Usage: mdai [options] [command]\n",
            "MDAI CLI is a command line interface to the MD.ai API.\n",
            "  See below for commands.\n",
            "Options:\n",
            "  -h, --help      display help for command\n",
            "Commands:\n",
            "  version         Get package version\n",
            "  config          View or set configuration variables\n",
            "  project         Project operations\n",
            "  dataset         Dataset operations\n",
            "  help [command]  display help for command\n",
            "   \n",
            "If you get an error that mdai could not be found (command not found or linux exit code 127), your PATH environment variable was not set up properly within your environment. Please go back and ensure that your PATH variable within your environment contains the directory where mdai was installed.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To install the MD.ai Command-line Interface (CLI), you need to download three files:\\n\\n1. For Windows: Download the zip file from this link: [Windows CLI](https://storage.googleapis.com/mdai-app-data/cli-releases/mdaicli{{ LATESTVERSION }}windows_amd64.zip)\\n\\n2. For MacOS: Download the zip file from this link: [MacOS CLI](https://storage.googleapis.com/mdai-app-data/cli-releases/mdaicli{{ LATESTVERSION }}darwin_amd64.zip)\\n\\n3. For Linux: Download the zip file from this link: [Linux CLI](https://storage.googleapis.com/mdai-app-data/cli-releases/mdaicli{{ LATESTVERSION }}linux_amd64.zip)\\n\\nAfter downloading the appropriate zip file for your platform, unzip the package. To run the `mdai` binary from any directory, make sure that the binary is available on the PATH. You can follow the instructions provided in the documentation for setting the PATH on your specific operating system:\\n\\n- [PATH instructions for Windows](https://stackoverflow.com/questions/1618280/where-can-i-set-path-to-make-exe-on-windows)\\n- [PATH instructions for Mac](https://www.architectryan.com/2012/10/02/add-to-the-path-on-mac-os-x-mountain-lion/)\\n- [PATH instructions for Linux](https://stackoverflow.com/questions/14637979/how-to-permanently-set-path-on-linux)\\n\\nOnce you have set up the PATH correctly, you can verify the installation by starting a new terminal session and running `mdai`. You should see the help output similar to the one provided in the documentation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YqevsV9ASopu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DiOvI4OSohi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}